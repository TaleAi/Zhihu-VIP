## 64.解开神经网络内部表征的缠结
DNN 在从数据中自动提取有意义的特征方面非常成功。我们通常不再需要人工介入的特征工程，可以专注于设计神经网络的架构。然而，由于神经网络的复杂性，提取的特征本身非常复杂并且通常不能被人类解释。 


深度学习系统至今一直被看作是一个黑盒子，很难解释人工神经网络是如何得出结论的。训练神经网络的唯一可见结果是节点之间连接权重的千兆字节大小的矩阵，因此问题的「解释」散布在数千个权重之间。我们不得不信任来自外部的评估指标，如训练和测试错误。 


表征学习（Representation Learning），即让系统自动发现和学习提取特征所需要的表征，是机器学习研究的核心。不管是过去流行的人工介入的特征工程，还是现在深度学习方法的隐式表征学习，算法的性能在很大程度上都依赖它们的输入表征的性质。尽管深度学习方法近年取得了成功，但它们仍远未达到生物智能的普遍性。 


以图像识别来说，深度学习并不理解要识别的构图对象，它常常会把噪声灰粒理解为某种小动物，或把一只昆虫理解为一辆汽车。这是因为输入表征的属性变量都纠缠在一起。例如，把一束光从不同角度打到一个杯子上，就会产生不同形状的影子，光照和杯子是完全不同的属性变量，一旦光照方向发生变动，在一幅图像中就会产生成千上万个像素的变化。同样的，如果把一个物体移动，那么整幅图像的大量像素都会变动，但是只有一个位置变量才是真正关键的变量。 


为了能够获取各种任务中最关键的属性特征，得知在训练数据之外泛化所必需的属性，许多研究人员已经提出不少解决方法，其中看上去很有前景的是解缠结表征（Disentangled Representation）方法，即设法解开神经网络内部表征的缠结，从而建立能在矢量中捕捉可解释因子的模型。 


解缠结表征的基本思路是定义单个单元，它对某个内部因子的变化非常敏感，而对其他因子的变化相对不敏感。例如，在 3D 物体的数据集上训练的模型可以学习对某个独立数据因子敏感的某个独立特征，如物体的身份、位置、比例、光照或颜色等。这样就通过解缠结表征把这些表征分解开来了，而且通常是可解释的，这样就可以用不同的独立特征来学习数据中变化的不同内部因子。 


使用解缠结表征的一个尝试是迁移学习。迁移学习是一种能够利用不同学习任务之间的共性来共享统计强度，并跨任务迁移知识的算法。表征学习算法对于此类任务具有优势，因为它们学习的是捕获相关因子的表征，因子的子集可能与某个特定任务相关，如图 11.4 所示。神经网络的隐藏层中的红色圆点为共享的解释因子，一些解释了输入，还有一些解释了每个任务的目标。 


在大多数学习解缠结表征的初步尝试中，都需要有关数据生成因子的监督知识，并将每个属性编码为特征矢量中的单独元素。这些方法仅限于表示固定数量的属性，一旦添加新属性，则需要重新训练，因此妨碍了将这些属性轻易地推广到特征空间来完成一个新任务。例如，在人脸识别任务中，在没有明确监督的情况下，学习到的特征很可能不会反映「微笑」和「张开嘴」两个属性之间的联系，也不会与性别和种族密切相关。这就出现了一些无监督的解缠结因子学习方法。 


![img](https://pic1.zhimg.com/v2-194c9f05f9208d62619fc6402b75b83c.webp)

数据的不同解释因子会在输入分布中彼此独立地改变，并且当考虑连续的现实世界输入的序列时，一次只有少数几个因子会改变。复杂数据会来自许多来源之间的丰富互动。这些因子在复杂的网络中相互作用，可能使与 AI 相关的任务（如图像分类）变得复杂。例如，图像由一个或多个光源之间的相互作用，以及物体形状和图像中存在的各种表面的材料特性组成。场景中物体的阴影可以以复杂的图形模式相互叠加在一起，造成没有物体边界的错觉，并且可以显著地影响所感知的物体形状。 


如何应对这些复杂的互动？怎样才能区分物体和阴影？最终，研究人员认为克服这些挑战的方法必须利用数据本身，即使用大量未标记的样例来学习将各种带有可解释性的来源分开的表征。诸如此类的考虑使我们得出结论：最有效的特征学习方法是尽可能多地解开因子的缠结，并尽可能少地丢弃相关数据的信息。 


迪德里克·金马（Diederik P. Kingma）等人在 2013 年提出的变分自动编码器（Variational Auto-Encoder，VAE）是一类重要的生成模型（另一类生成模型是 11.4.2 节将讨论的 GAN）。VAE 能够从高度复杂的输入空间中解开纠缠在一起的简单数据生成因子，这已经得到证明。例如，当输入人脸图像时，VAE 可使用一个隐藏变量，自动学习来对面部打光的方向编码。训练之后，可以改变每个隐藏变量并观察对输出的影响，这样就可以人工分析模型所学习的特征类型。 


到目前为止，VAE（和其他生成模型）在图像领域很成功，其中大多数体系结构基于卷积神经网络（CNN），它们本身就是强大的特征提取器。但是在时间序列或离散域的应用中，如音乐和语言处理等，它的成功很有限。 


图 11.5 为 VAE 的构成。在 VAE 中，数据沿着编码器到解码器的顺序，先被压缩，然后被展开。压缩数据是为了从原始数据中提取最关键的本质信息，如果以一个动物为例，即相当于提取出「骨骼」的特征量。解码器主要通过充实这个「骨架」，即加入「肌肉」以再生数据。这时，我们可以利用概率逐渐改变「肌肉」的结构。因为有了「骨骼」，就能够在不损坏数据本质的情况下创造出新的数据。 


![img](https://pic2.zhimg.com/v2-b45c6db16ce18138e82d2dc1234658bf.webp)

VAE 有几个扩展型，如 β-VAE  [202,  203]  主要集中在解缠结的应用，并引入解缠结指标，使评估更容易。这些尝试的结果改进了现有的学习解缠结表征的方法，深入研究了如何衡量解缠结的结果，并尝试学习时间序列任务的解缠结表征。β-VAE 方法可以在没有监督的情况下学习数据生成因子的可解释表征。这种能力正是人类智能发展的一个重要前提，是用接近人类的方式来学习和推理。 


β-VAE 方法是对 VAE 框架的修改，它引入了一个可调节的超参数 β，可以平衡潜在的通道容量和独立约束，并重新建立精度。根据研究结果，适当调整的 β >1 定性，效果大大优于 VAE（β=1）及解决各种解缠结因子学习方面问题的现有技术，如无监督（InfoGAN）  [204]  和半监督（DC-IGN）  [205]  等方法。 


β-VAE 对训练是稳定的，对数据作出很少的假设并且依赖对单个超参数 β 的调整，可以通过使用弱标记数据的超参数搜索，或通过针对无监督数据的启发式视觉检查来直接优化。对网络内部表征解缠结的方法，使神经网络更容易被人类理解，并帮助神经网络更快地学习新数据，因为它从一开始就使不关联的表征因子脱离开来，只对特定的表征进行学习。 


另外，谷歌旗下的 DeepMind 也在 2019 年 5 月发布了一种显式关系性神经网络架构  [206]  ，把深度学习和符号化表征连接起来，而且着重表征了多任务通用和重复使用能力，达成了一定程度的可解释表征。这个新网络架构被称为 PrediNet，它学习到的表征中的不同部分可以直接对应命题、关系和对象，关键就是具有一定的关系解缠结能力，这也正是得到能学习到良好表征的模型所必需的。 


内部表征可以对多种任务都通用，而且可重复使用，这种能力在目前的机器学习中还相当缺乏，但这正是人类最基本的能力，即人脑可以从不少相似或接近的事情中获得灵感，从而也给人类带来了很高的数据效率、迁移学习的能力和泛化到不同数据分布的能力，这些能力对终身学习、持续学习来说也是非常重要的。 


备案号:YX01jbkWgwB9w7Lle

