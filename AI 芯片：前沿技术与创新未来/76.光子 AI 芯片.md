## 76.光子 AI 芯片
长期以来，光学计算机一直被认为是信息处理最前沿、最令人向往的设备，因为它具有大带宽和低功耗计算的潜力。经过 30 年的技术积累，光学计算走过了低潮，慢慢进入了量子时代的复苏阶段。让我们先回顾一下光学计算的简史。 


20 世纪 80 年代，贝尔实验室的科学家最早尝试制造光学计算机。这种新型计算机的带宽可达数百太赫兹，明显大于电子设备几千兆赫兹的带宽。到了 20 世纪 80 年代中期，人们对这项技术的期望达到了高潮。当时，贝尔实验室的一位人士在美国《纽约时报》上如此预测：「到 20 世纪 90 年代中期，我们将拥有灵活的可编程计算机。你可能永远不知道其中有光学器件。你会看到没有闪烁的灯光，看起来很沉闷，但它会围绕其他一切器件运行。电子产品跟不上我们。」 


贝尔实验室的光学计算方法是一种基于电子晶体管原理的光学晶体管版本，即一种用于切换（或放大）光信号的器件。与手机和计算机内部晶体管里面的电子不同，光束不会直接相互作用。然而，光可以与材料相互作用：通过暂时改变它通过的材料的特性，一个光束的通道可以被另一个光束「感觉到」。这种光学晶体管的开关工作方式如图 13.1 所示。 


![img](https://pic1.zhimg.com/v2-0eecefbbe557c06a2115f710c2e85fcf.webp)

但遗憾的是，贝尔实验室的科学家的预测并没有实现。这主要是由于实现光学晶体管非常困难。每个光学晶体管都会吸收一些光，使光信号在传播时会逐渐变弱，这就限制了可在这种系统上执行的操作次数。最重要的是，如何用光来存储数据是个大问题，这个问题至今仍然极具挑战性。由于 20 世纪 80 年代未实现承诺，科学界对光学计算研究产生了怀疑和争议。 


然而，虽然光学晶体管失败了，但一种新的光学计算方法又被发明出来。20 世纪 90 年代中期，由于新的证据表明量子系统可以解决在经典计算机上难以解决的问题，量子计算迅速发展。有许多已知的方法来实现量子系统，包括使用光子（单个粒子）。1994 年，为了构建光学量子处理器，迈克尔·雷克（Michael Reck）及其合作者描述了一种使用基本光学元件阵列的系统来执行被称为矩阵乘法的重要数学运算，被称为 Mach-Zehnder 干涉仪（Mach-Zehnder Interferometer，MZI）。 


这种用基本光学元件搭建的系统，使用笨重的光学部件进行光学实验，这些光学部件被拧入光学桌面（控制振动的金属表面，通常称为面包板），以达到机械稳定性。但是，利用这种面包板平台，难以处理具有数十个以同步节拍运行的光束，即使很小的振动或温度变化也会给系统带来误差。因此，虽然把小型光学回路连接成一台更大的光学计算机是一个革命性的想法，但使其成为真正实用的技术的可能性很小。 


构建一个光学神经网络需要相位稳定性和大量的神经元。由于传统光学实验系统通常组装在室内的金属桌上，占用空间较大，利用大量的光学部件（如光纤和透镜）进行此类转换已成为主要障碍。集成光子学（如硅光芯片）的出现为相位稳定的大型光学转换提供了可扩展的解决方案（见图 13.2）。 


![img](https://pic1.zhimg.com/v2-7b35b5d4539ccd6fd15ffe99a54e624a.webp)

#### 硅光芯片


随着半导体芯片工艺的进步，原来放在桌上的一大堆光学部件逐渐被集成光子芯片取代（见图 13.2）。这种光子芯片（常常在硅基材料上制成，因此也称为硅光芯片）将仪表大小的光学部件缩小至微米和纳米级，而且这些元件易于制造和控制。由于对作为当今互联网骨干的光纤网络技术的重视，电信行业一直在积极开发硅光芯片。然而，直到 2004 年左右，制造具有大量元件的硅光集成电路才变得可行。 


目前，基于硅纳米光子学的硅光芯片技术正成为用于生产通用光子集成电路的成熟技术。到 2012 年，硅光芯片制造工厂开始为硅基光学芯片提供多项目晶圆（Multi-Project Wafer，MPW）服务。这使得很多学术研究小组能够以较低的成本共享资源，并以很低的数量设计生产研究型芯片。 


传统 CMOS 芯片的所有功能都由晶体管、电阻器、二极管和电容器组合执行，但是硅光芯片的基本构件非常多样化，并且有不同的要求。首先，要使用低损耗波导来引导光。光的分配和布线还需要有效的分路器和波导交叉器。将芯片的光输入和输出与光纤耦合也是一项非常具有挑战性的任务，特别是对于深亚微米硅波导来说。由于光纤支持两个光偏振，但片上波导通常是偏振敏感的，这使得实现起来更加困难。 


光在频谱上的覆盖范围很宽。大多数硅光技术支持 1310nm 和 1550nm 附近的近红外波段。硅光芯片的基本功能涉及光电转换。将光信号转换为电信号可以用光敏二极管完成，光敏二极管在硅光子学中通常用锗实现。可以使用相位或幅度调制将电信号转到光学载体上，这可以通过用嵌入式二极管或电容器修改硅波导中的电载流子密度来完成。作为光源的激光器可以在 Ⅲ-Ⅴ 族技术平台中单片集成，但在硅光芯片中，光源必须键合或耦合到片外。 


硅光芯片对工艺提出了与 CMOS 芯片不同的要求。波导的层厚可能与晶体管不同，并且光学质量（如不希望的光吸收等）是重要的附加要求。此外，硅光子波导非常敏感，这对制造过程提出了纳米级的公差要求。 


制造硅光芯片比传统电子 CMOS 器件便宜，不需要最先进的半导体工艺，如 7nm 或 5nm 工艺节点，而是可以使用更老、更便宜的工艺节点来制造。 


由于硅光元件需要控制和驱动功能，因此需要与电子元器件集成。这可以是单片集成，在相同的晶圆级工艺中结合光学和电子元器件，也可以通过混合 3D 集成。随着光子芯片变得越来越复杂，电子功能集成度越来越高，这对芯片设计提出了新的要求。 


光的并行性是光所具备的固有优势，以前曾激励研究人员探索使用光实现神经网络的方法。然而，这些网络的许多光学实现依赖笨重的折射元件，导致尺寸大且很难对准，因而阻碍了平台的广泛使用。近年来，随着硅光技术的成熟，人们对该领域的兴趣愈加浓厚，光学神经网络已有数个演示，而基于硅光技术来实现的深度学习加速芯片也已经崭露头角。 


#### 光学神经网络架构


2012 年，MIT 的尼古拉斯·哈里斯（Nicholas Harris，现任 Lightmatter 首席执行官）和合作者使用 OpSIS MPW 服务实现了可编程纳米光子处理器（Programmable Nanophotonic Processor，PNP），这是一种采用硅光技术实现光学矩阵变换的光学处理器。实施大规模 PNP 存在两个主要技术挑战：一个是紧凑、低损耗、高效能的移相器；另一个是多通道控制和读出电路。关于 PNP 及其在量子信息处理中的应用的第一篇研究论文于 2015 年发表。 


光学神经网络（Optical Neural Network，ONN）架构如图 13.3a 所示，信号以在集成光子波导中传播的光脉冲幅度进行编码，并在其中通过光学干涉单元（Optical Interference Unit，OIU），最后通过光学非线性单元（Optical Nonlinearity Unit，ONU）。光学矩阵乘法通过 OIU 实现，非线性激活通过 ONU 实现。 


为了实现一个可以实现任何实数值矩阵乘法的 OIU，需要使用奇异值分解（Singular Value Decomposition，SVD），因为一般的实数值矩阵 w  (i)  （加权矩阵）可以分解为 w  (i)  =UΣV  \*  ，其中 U 是一个 m×m 的酉矩阵，Σ 是一个 m×n 的对角矩阵，在对角线上有非负实数，V  \*  是 n×n 酉矩阵 V 的复数共轭。从理论上已经证明了任何酉变换 U、V  \*  可以用光学分束器和移相器实现。以这种方式实现的矩阵乘法原则上不消耗功率。深度学习计算的主要部分涉及矩阵乘积，这一事实使得此处介绍的 ONN 架构具有极高的能效。 


基于 SVD 的 OIU 示意图如图 13.3b 所示  [225]  ，它由 56 个可编程 MZI 单元组成，每个单元都有两个 50：50 功率分配器。OIU 使用硅光芯片实现。就 MZI 而言，SVD 的实现如图 13.3c 所示。Σ  (i)  的元素可以使用图 13.3c 中 Σ  (i)  模块所示 MZI 的内部移相器来配置，为 Σ  (i)  j  j=sinθ  j  j  /2。除光衰减技术外，Σ  (i)  也可以使用半导体这样的光学放大材料来实现。ONU 可以使用光学非线性来实现，如饱和光吸收和双稳态，这些非线性已分别在光子回路中得到证明。因此，对于输入强度 I  i  n  ，光输出强度可由一个非线性函数 I  o  u  t  =f(I  i  n  )给出。 


在图 13.3 中，图 13.3a 表示一个多层光学神经网络。左侧有表示输入矢量的光脉冲。每层由一个实现权重矩阵 w  (i)  的 OIU 和一个实现激活函数 g 的 ONU 组成。图 13.3b 为 OIU 和 ONU 的详细框图。图 13.3c 为 OIU 实现，使用了一个衰减器（Σ  (i)  ）和两个 PNP。一个 PNP 用于实现 V  (i)  ，另一个实现 U  (i)  。 


由于 PNP 可以实现一般矩阵运算，因此它的应用领域很广，包括经典计算、量子计算、数据路由、安全等方面。2018 年，哈里斯和麻省理工学院的其他合作者发表了一篇关于线性 PNP 的论文  [226]  ，该论文介绍了 PNP 的最新进展及对全光学神经网络的应用。在该工作中，整个 DNN 使用非线性光学器件（光学晶体管的基本版本）接合在一起的许多个 PNP 来实现。这种用光子芯片实现的 DNN，不但可用于推理，还可用于训练。 


![img](https://pic4.zhimg.com/v2-a1d67af4e9a677a845ddc0972e8aa3a0.webp)

#### 光子 AI 芯片


虽然光学矩阵处理技术日趋成熟，但 AI 矩阵处理器领域却发生了重大变化。2017 年，谷歌发布了用于深度学习的矩阵处理器 TPU。DNN 的核心是矩阵乘积累加单元（详见第 3 章）。因此，为此任务构建矩阵处理器非常有意义。 


哈里斯等麻省理工学院的研究人员已经通过实验展示了片上光学神经形态计算  [227]  ，使用全连接的神经网络算法，达到了与传统数字计算机相当的准确性。实验表明，在某些条件下，光神经网络体系结构可以在前向传播上至少快两个数量级，同时神经元数量与功耗之间可以保持线性关系。这类光子类脑芯片中的光脉冲处理，现在已经有很多选择，如使用半导体激光器、光子晶体纳米腔等。 


事实证明，实现可扩展的冯·诺依曼光学计算机具有挑战性，但以硅光芯片实现的人工神经网络可以利用其固有特性（如其对非线性的较弱要求）来实现实用的全光学计算应用。与在当前电子计算机上实现的常规人工神经网络相比，光学神经网络架构可以显著提高能效。由于硅光系统的特殊性质，它能够实现比电子 AI 加速器更快、更节能的矩阵 MAC 处理器。在时延、吞吐量和能效方面都要优于电子 MAC 处理器几个数量级。硅光 AI 加速器可以在一个 CPU 时钟周期内执行任何矩阵乘法（无论矩阵大小），而电子芯片至少需要几百个时钟周期才能执行相同的操作。 


硅光器件不受基于晶体管的电子电路的物理特性的约束——它开启了一条新途径，可以在实际功率范围内延续目前每单位面积计算量呈指数级增长的趋势。虽然研究人员仍然没有计划创建完全成熟的光学计算机，但该技术适用于特定类型的计算，尤其非常擅长实现的算法之一是深度学习最需要的矩阵乘法。 


2019 年，哈里斯成立了 Lightmatter，用晶体管和硅光器件制作了第一个用于推理的 AI 芯片，包含了超过 10 亿个晶体管。该公司在 2020 年 8 月对外展示了这款芯片，获得业界高度评价。这款芯片称为 Mars，将于 2021 年正式商用。Lightmatter 采用不同的方法来处理 DNN，但与 TPU 采用的 2D MAC 阵列有许多相似之处。Lightmatter 的方法基于 PNP 架构，依赖硅光工艺中制造的 2D MZI 阵列。为了实现 N×N 矩阵乘积，该方法需要 N  2  个 MZI，这与脉动式 MAC 阵列使用的计算元素数量相同。在数学上，每个 MZI 执行 2×2 矩阵矢量乘积。总之，MZI 的整个网格将 N×N 矩阵乘以 N 个元素的矢量。光在大约仅 100 ps 的光学信号飞行时间内就从 MZI 阵列的输入传输到输出从而完成了计算，计算时间小于电子计算的单个时钟周期。由于该系统在较短的光学波长下工作，MZI 的理论带宽接近 200 THz。相比之下，电子 MAC 的带宽仅几吉赫兹。另外，MZI 每次计算所需的能量比最新的电子芯片中实现的电子 MAC 要低几个数量级。 


MZI 需要有一个电子移相器来控制。有不少种移相器可供选择：热移相器通常很慢，频率在千赫兹范围内；PN 结很快但太大，通常用于高端光学器件。Lightmatter 选择了纳米光学机电系统（NOEMS），这种系统使用少量电荷来移动波导，损耗非常小，并且静态功耗几乎为零。它的工作速度为几百兆赫兹，因此 Mars 芯片的工作频率为 1 GHz。 


光子芯片需要电子电路完成控制、存储等功能。因此，Mars 芯片除了一个基于硅光器件的光子内核外，还包含一个 SoC。这个 SoC 很小，但具有 30 MB 容量的 SRAM 用于缓存。这些存储容量不足以运行大型模型，但对于较小的模型则足够了。Mars 使用 3D 集成（见图 13.4），这样可以节省更多电量，因为数据不必在芯片之间传输很长的距离。 


![img](https://pic4.zhimg.com/v2-c04e778074f67c9bf9bdb958047134ab.webp)

  



备案号:YX01jbkWgwB9w7Lle

