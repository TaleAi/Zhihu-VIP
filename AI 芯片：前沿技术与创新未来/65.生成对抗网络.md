## 65.生成对抗网络
现在，人脸识别技术已经非常普及，并已成为 AI 的重要应用之一。如果 AI 可以归纳分类出每个人的人脸，那么能否让 AI 根据人脸的特征创造出人脸，或根据照片创作出一幅有特定风格的艺术画作呢？ 


自 2014 年伊恩·古德费洛（Ian J. Goodfellow）  [207]  等人发明了 GAN 之后，GAN 作为一种强大的无监督学习方法得到了迅猛发展。它是《麻省理工科技评论》（MIT Technology Review）报告的 2018 年十大突破性技术之一。GAN 在图像生成、视频预测和自动驾驶等许多领域中已开始发挥重要作用，成为当前的热点。基于 GAN 算法的产品甚至已经得到了商业化应用。 


利用 GAN 算法，可以让 AI 学习和模仿几乎任何数据分布，因此可以被训练在很多领域中创作，如图像、音乐、演讲、小说、散文、诗歌等，其作品能做到与现实世界极其相似。因此，GAN 可以部分解决人类智能中很关键的创造性问题。GAN 被很多研究人员称为「下一代 AI 算法」，因为它不仅能够用于识别和分类，而且可以生成和联想，这就让 AI 迈向人类智力水平的征程又上了一个台阶。 


GAN 由两个 DNN 组成，即一个生成器 G 和一个鉴别器 D，这两个模型相互竞争、相互加强。与传统的神经网络不同，GAN 采用博弈论方法，能够通过双人博弈从训练分布中生成目标。由于应用了对抗性学习方法，训练过程不需要近似难以处理的概率分布函数。此外，使用生成器的时候，只需用随机数驱动它。由于对用作 G 和 D 的 DNN 类型没有限制，因此可以根据要生成的数据和目的来选择适当类型的 DNN。例如，生成图像时，可以选用对图像处理非常有效的 CNN，而如要生成时间序列数据的语音和文本，则选 RNN 或 LSTM（见图 11.6）。 


![img](https://pic1.zhimg.com/v2-3a69ab9e3ec69675f1b15dbde178cae1.webp)

GAN 可以被看作反向的深度学习识别器。在用于图像识别的深度学习中，复杂的大数据被输入 DNN 中，在其中逐渐被压缩。例如，如果输入猫图像，它将提取猫的特征信息，同时丢弃详细的附带信息，如与猫无关的背景和猫的类型，最后压缩到 1 位信息，即「1」（是猫）或「0」（不是猫）。 


GAN 里所使用的 DNN 遵循与此相反的过程。随机数除了平均值和方差之外，是信息量为零的数据，当输入该数据后，经过 DNN 处理，再添加数据，最终输出一幅高清晰度图像。从信息量为零，到一幅高清图像，听上去不可思议，而这正是 GAN 最主要的特色：它具有信息放大的作用，从输入到输出，不是一般的 DNN 所起的函数作用，而是会增加新的信息量。 


在训练之前，生成器 G 先创建图像。这个过程比较简单。首先，使用正态或均匀分布对一些噪声 z 进行采样。如果使用 z 作为输入，用生成器 G 即可创建出图像 x［x=G（z）］。从概念上讲，z 表示所生成图像的潜在特征，如颜色和形状。在深度学习分类中，不控制模型正在学习的特征。类似地，在 GAN 中，不控制 z 的语义，即不控制 z 中的哪个字节决定图像某部分的颜色，而让训练过程学习它。为了发现它的语义，最有效的方法是绘制生成的图像并检查。 


我们可以像训练 DNN 分类器一样来训练鉴别器。输出 D（x）是输入实数 x 的概率，即 P（x）。如果输入是真的照片，则 D（x）=1；如果是生成的图片，则 D（x）=0。通过该过程，鉴别器识别对真实图像有贡献的特征。同时，希望生成器创建 D（x）=1（匹配真实照片）的图像。因此，可以通过反向传播来训练生成器，这个目标值一直返回到生成器，即训练生成器产生接近鉴别器认为是真实的图像。 


GAN 以交替的步骤训练两个 DNN，并将它们锁定在激烈的竞争中以改善自己。最终，鉴别器识别真实图像和生成图像之间的微小差异，而生成器的目标是创建鉴别器无法区分的图像。GAN 模型最终收敛并产生一幅自然的图像。 


这种鉴别器概念也应用于许多现有的深度学习解决方案中，让一个鉴别器作为一个评判者，然后反馈检查到的差异，使 DNN 工作得更好。 


总的来说，生成数据的概念有巨大的潜力，但遗憾的是也存在很大的危险。除了 GAN 之外，还有许多其他的生成模型。例如，由特斯拉的马斯克资助的 OpenAI 研发了 GPT-2。由 GPT-2 生成的文章段落看起来已经像记者所写的内容。然而，OpenAI 已经决定不公开其数据集和训练模型，因为它可能被误用。2020 年 6 月，规模更大的 GPT-3 也已问世，但仍限于内部测试使用。 


VAE 的问题是输出数据的精度较低，这是因为利用概率只是粗略地近似，而且数据的检查是按照人的想法进行的。而 GAN 作了很大改进，它不使用近似概率，编码器被转换为输出数据的「检查官」，以使生成方法和检查方法同时进行深度学习。尽管如此，GAN 还是难以生成真实和高清的图像。 


解决这个问题的突破是英伟达在 2017 年 10 月宣布的渐进式 GAN。它可以输出前所未有的高清晰度和非常逼真的 1024 像素 ×1024 像素人脸图像，这让世界各地的研究人员感到惊讶。很多人把它称为第二代 GAN（GAN 2.0）。图 11.7 为英伟达利用数据组 CELEBA-HQ 和渐进式 GAN 生成的 1024 像素 ×1024 像素明星图像。图像由使用随机噪声 z 的渐进式 GAN 生成，第一次达到了商业级应用水平  [208]  。 


![img](https://pic4.zhimg.com/v2-7511ffd94be0c50a58ca6fb658c14f37.webp)

对于这些人脸照片，GAN 甚至还可以选取某几张脸的特征，通过把这些脸部特征组合在一起，以特定比例合成并创造出一张新的脸。有人把 GAN 的这个功能称为人工基因控制。 


由于 GAN 受到人们的普遍追捧，大量的衍生技术（大部分是 VAE 和 GAN 的混合型）涌现出来，目前已经有 1000 种左右，而且数量还在不断增长。下面简单介绍几个衍生技术及其应用的例子。 


（1）CGAN（Conditional GAN）：最初的 GAN 在使用时仅使用随机数，但仅此一项无法控制输出。CGAN 对此作了改进，即允许在输入随机数的同时，向 GAN 输入请求来控制要输出的数据。这是通过学习请求的内容和当时要成对输出的数据来实现的。这种 GAN 已经应用于人体姿势转换。通过人体姿势的附加输入，可以将图像里的人转换为不同的姿势。 


（2）CycleGAN：这种 GAN 可能是第一批 GAN 的商业应用  [209]  实现。它可以将图像从一个域（如真实场景）转换到另一个域（如梵高或徐悲鸿的绘画风格，见图 11.8）。CycleGAN 打破了必须使用包含成对图片的数据集来进行训练这一传统限制。它不使用随机数，通过对源域图像进行两步变换（即首先尝试将其映射到目标域，然后返回源域得到二次生成图像），在多次的粗略配对中降低损失，这样就能够降低风格转换时对配对数据库的要求。 


![img](https://pic4.zhimg.com/v2-f9f84cf7cb413a66fbde00f73a1eb394.webp)

（3）PixelDTGAN：名人穿戴的衣服、帽子、鞋子等的款式，常常成为购物者追求的流行样式。PixelDTGAN 可以根据名人照片来创建各式服装图片和款式，这已经用于电子商务的商品推荐。 


（4）StackGAN：把文本转换为图像是 GAN 较早的应用之一。只要输入一个句子，就可生成符合描述的多幅图像。文本和图像内容不一定必须直接相关，例如一句「草原上的马在奔跑」，可能会有几百种的图像显示。 


GAN 最近已成为深度学习中的一种很特别的、有极大商业价值的算法，而基于 GAN 的加速器芯片也正在积极研发中。 


GAN 在其生成模型中使用了一种新型的数学运算法，称为转置卷积（Transposed Convolution），也称为反卷积（Deconvolution）。对于传统的基于 DNN 的各种 AI 芯片，这种运算的执行效率很低。这是因为生成器（转置卷积）的主要操作不同于鉴别器（传统卷积）中的操作。卷积操作是把输入缩小，而转置是通过先在其行和列中插入零来扩展它，然后在此扩展输入上滑动窗口以执行一系列乘积累加。零的插入使得转置卷积和传统卷积的本质与硬件加速器不同，因为它导致了传统加速器中的无效操作（乘以零），这种无效操作占用了大量计算资源。 


如果要绕过零而避免冗余计算，则需要处理非结构化存储器访问和不规则数据布局的技术。因此，GAN 加速器必须能够适应转置卷积，优化非结构化数据访问，并且支持多个 DNN 的训练。 


GAN 所需的独特训练过程使其难以在现有的神经网络加速平台上运行：两个相互竞争的网络同时在 GAN 中共同训练，显著增加了对内存和计算资源的需求；而 GAN 中的不同 DNN 具有不同的计算和内存带宽要求，从而导致不同的处理瓶颈。此外，由于 GAN 生成高分辨率图像，因此还需要高吞吐量的推理和训练体系结构。这些都限制了 GAN 在图像和视频应用之外的任何规模的通用硬件的使用。虽然到目前为止还没有看到任何 AI 芯片初创公司专注于 GAN 加速器的开发，但是学术界已经展示了具有 GAN 功能的 AI 芯片的原型。 


#### 生成对抗网络的 FPGA 实现


阿米尔·亚兹丹巴赫什（Amir Yazdanbakhsh）等研究人员在 2018 年提出了一种适用于 GAN 的新架构，并用 FPGA 实现  [210]  。该架构允许计算引擎分组在 SIMD 模式下运行，同时每个组运行自己的指令。由于 SIMD 单元将访问不同的存储位置，因此它们的架构将数据检索与每个单独计算引擎内的数据处理分开。为了使转置卷积及传统卷积运算的数据得到最大程度的重用，也需要正确处理处理单元之间的数据移动。 


此架构被设计为一个完整的堆栈，称为 FlexiGAN。FlexiGAN 带有一个编译工作流程，该工作流程从 GAN 的高级规范开始，重新排序计算，优化数据流，分离数据检索，并生成两级指令层次结构以加速给定的 GAN，并在赛灵思 XCVU13P 的 FPGA 上做成了 GAN 加速器。如将这个加速器与仅支持传统卷积的类似优化设计进行比较，它可提供 2.2 倍或更高的性能。而且这个加速器有足够的通用性，可以在同一 FPGA 平台上有效地加速多种生成和鉴别模型。 


#### 生成对抗网络的 CMOS 实现


2020 年 2 月，韩国 KAIST 的研究人员展示了一款称为 GANPU 的 AI 芯片  [211]  ，这是一种针对 GAN 优化的节能型多 DNN 训练处理芯片。它具备 3 个关键功能：支持多个 DNN 的自适应时空工作负载多路复用（ASTM），用于高吞吐量推理和训练的输入和输出激活稀疏性利用功能（IOAS），以及指数 ReLU 推测功能（EORS）。ASTM 在运行多个 DNN 的同时，通过一个可重构累积网络（RAN）保持较高的处理器利用率。IOAS 架构可对输入激活（IA）和输出激活（OA）的稀疏性进行判断，零值均被跳过，以在 DNN 推理和训练的所有步骤中实现高吞吐量和高能效。EORS 可以使用权重和激活的指数值来预测未知的 OA 稀疏性。 


这款芯片由 8×4 个双稀疏感知训练核（Dual Sparsity-aware Training Core，DSTC）、8 个长时存储器、1 个 RAN 和 1 个顶级 RISC 控制器组成。每个 DSTC 包含 1 个由 6×7 个处理单元（PE）组成的阵列、1 个 EORS 单元、累加单元、18 KB 权重存储器及 IA 和 OA 的缓冲区，集成了浮点 MAC 单元以保持训练和推理质量。该芯片的特点是解决了处理多个 DNN 时在时域出现的计算量或存储量峰值过高的瓶颈，以及在空域出现的计算或存储能力空闲的问题，采用了自适应方法来对此进行优化（见图 11.9）。 


![img](https://pic1.zhimg.com/v2-a9cdf4594040c4767a844ea2016b3e44.webp)

GANPU 工作于 0.7～1.1 V 电源电压，功耗分别为 58mW 和 647mW，达到了较高的能效，最大频率为 200 MHz。DNN 计算的最高性能为无稀疏性时的 538 GFLOPS（fp16）和 1.08 TFLOPS（fp8），而在 IA 和 OA 的稀疏度均为 90% 时，最高可达 14.03 TFLOPS（fp16）和 24.13 TFLOPS（fp8）。在作为每次推理需要 99.10 GFLOPS 的 CycleGAN  [209]  生成器时，GANPU 的处理能力在最大频率下达到 10.26 f/s，能效提高了 76.25%。GANPU 采用 65nm CMOS 工艺制造，面积为 32.4 mm  2  。 


GANPU 在芯片架构上作了很多创新，以应对处理多个 DNN 的挑战。这种架构为下一代基于 GAN 的 AI 加速器的研发创造了条件。 


#### 生成对抗网络的 RRAM 实现


陈怡然等人提出了一种基于 RRAM 的存内计算 GAN 架构，称为 ReGAN  [212]  ，可以有效地减少片外存储器访问。 


首先，研究人员分析了 GAN 中的一般训练过程，包括正向传播和反向传播。然后根据这样的计算路径，提出了一种流水线架构，以利用结构化逐层计算来提高系统吞吐量。该架构直接利用 RRAM 单元执行计算，而无须额外的处理单元。RRAM 用作存储中间结果的缓冲区。这样的设计可以让数据无须跨存储层次传输，从而极大地减少了数据移动并降低了能耗。 


ReGAN 包含新提出的空间并行和计算共享技术，以进一步提高 GAN 中的并行性，从而更有效地支持训练。 


ReGAN 将 RRAM 划分为 3 个区域：存储子阵列、全功能子阵列和缓冲区子阵列。存储子阵列与普通内存阵列相同，具有数据存储功能。全功能子阵列可以设置为计算和存储两种模式。在计算模式下，全功能子阵列执行矩阵矢量乘法；在存储模式下，它们用作数据存储的存储子阵列。最接近全功能子阵列的存储子阵列被用作缓冲器，用于存储各层之间的中间结果（如生成的图像数据等）。 


ReGAN 是按照脉冲神经网络（SNN）的架构来设计的。比较特别的是执行 GAN 训练的流水线设计。当输入数据被存到缓冲区中时，全功能子阵列开始计算。当第一个输入矢量被发送到 RRAM 交叉开关时，字线驱动器可以继续处理下一个输入矢量。输入分别与两个具有正权重和负权重的交叉开关逐个相乘。「整合—激发」电路在位线上收集电流，并产生代表结果的输出脉冲。激活功能单元对结果执行非线性函数计算。中间数据（如部分和、导数等）存储在缓冲区中。当每一层计算完成或缓冲区已满时，结果将写回到存储子阵列中。 


实验结果表明，ReGAN 与 GPU 平台相比平均可实现 240 倍的性能提升，平均能效提高了 94 倍。 


另外一款基于 RRAM 的 GAN 芯片称为 LerGAN  [213]  ，也是一种存内计算 GAN 架构。LerGAN 提出了一种去除零的数据重塑方案，以消除与零相关的计算；同时提出了一种可重构的互连方案，以减少数据传输开销。 


这种 3D 连接的存内计算可以根据传播和更新的数据流动态地重新配置内部的连接，从而在很大程度上减少了数据移动，避免了 I/O 成为训练 GAN 的瓶颈。 


实验表明，与基于 FPGA 的 GAN 加速器、GPU 平台和基于 RRAM 的常规 DNN 加速器相比，LerGAN 分别实现了 47.2 倍、21.42 倍和 7.46 倍的加速，以及 1.04 倍、9.75 倍和 7.68 倍的能效提升。 


GAN 开发的最初几年已经取得了令人瞩目的进展。使用 GAN 得到的成像结果，精度可以高到与实际拍摄影像没有区别的程度。然而，不只是图像和图片，在未来几年，随着 GAN 专用芯片的开发及进入市场，GAN 生成的高质量视频可能会出现。语音交互、无人机、机器人、三维建模等越来越多的领域也开始引入 GAN 技术。 


备案号:YX01jbkWgwB9w7Lle

