## 40.冯·诺依曼架构与存内计算架构
目前的计算系统，包括智能手机在内，都是基于冯·诺依曼架构，即处理单元与存储器是物理上分开的，面临着大量数据在处理单元和存储器之间来回移动所产生的能耗和时延问题，这有时被称为「内存墙」。这个问题在一些由 AI 加速器芯片组成的 AI 系统中已经成为一个严重的计算效率瓶颈。根据在 AI 推理芯片上的测试  [120]  ，单个整数 MAC 操作可能仅需要约 3.2 pJ 的能量，但如果将权重值存储在片外 DRAM 中并送至处理器进行计算，则仅获取卷积核值就需要约 640 pJ 的能量。这个问题在深度学习算法的训练阶段更加普遍，在这个阶段，必须学习或频繁更新数亿个权重值。存储器访问的能量消耗将使整体的计算不堪重负。 


如图 7.1 所示，当前的数字计算机由执行操作的处理器和将数据及程序存储在单独芯片中的主存储器组成。这些芯片通过数据总线连接，形成了冯·诺依曼架构的基本配置。随着处理器和存储器变得速度更快并且功耗降低，由总线中充电和放电的布线容量引起的对通信带宽的限制和功耗增加已经变得突出，这就是所谓的冯·诺依曼瓶颈。 


为了缓解这种情况，如图 7.1 中右图所示，大量的小型处理单元和本地存储器并行连接到 GPU 或专用 AI 处理器中的芯片上，这种直接在存储器上执行操作的方法称为存内计算。在由交叉开关阵列组成的 NVM 中，模拟权重值被本地存储在交叉开关器件中，以最大限度地减少训练过程中的数据移动。一些实验结果表明，使用合适的存内计算，可以将训练速度提高 4 个数量级以上。存内计算也使得一些边缘侧设备可以启用更复杂的推理算法。 


![img](https://pic4.zhimg.com/v2-75e37e2b9c452dcc2ff0fb3d67cf5650.webp)

虽然存内计算这个想法已经提出至少 40 年了，但是这种方法过去没有被大规模商业应用，而是在近 10 年才越来越得到产业界的重视，其主要原因有以下几个方面。 


（1）存储技术没有像今天这样面临着严峻的扩展挑战，数据的爆炸式增长也是最近几年遇到的严重问题，数据移动瓶颈对系统成本、能源和性能的影响也不如今天这么大。 


（2）以前虽然有不少学术研究，但并没有厂商真正想把这个想法落实到产品。在 2010 年左右，惠普成为提出「以存储器为中心」和「以数据为中心」的大公司之一，试图把之前传统的以处理器为中心的产品思路扭转过来。惠普在当时计划的「The Machine」新项目中，提出了「近内存计算」和「存内计算」的方案（惠普也是第一家做出忆阻器原型的公司）。 


（3）在过去，很难将处理单元与 DRAM 集成在一起。在单个芯片上合并 DRAM 和逻辑电路，意味着 DRAM 的设计需采用更昂贵的逻辑电路工艺，或逻辑电路设计采用针对 DRAM 优化的工艺。存储器行业对成本非常敏感，存内计算模式下每比特成本将不可避免地增加。此外，要真的利用好存内计算，需要程序员用新的编程模型来解决问题。 


（4）近年来，随着新型 NVM 的发展，存内计算有了合适的核心器件。由于现代内存架构的不断进步，研究人员在近期探索了一系列用于多种不同目的的存内计算架构，如以 3D 堆叠方式集成逻辑和内存。 


现在大部分存内计算应用还是在使用现有的存储器技术，为专门应用而构建。这些应用包括两大类： 


（1）数据库领域将存内计算用于缓存和其他应用； 


（2）在芯片中使用存内计算技术，以处理神经网络和其他应用在内存中的计算任务。 


多年来，甲骨文（Oracle）、SAP 等公司已在数据库领域使用存内计算。数据库在计算机中存储并提供数据。在传统的数据库中，数据被存储在磁盘驱动器中，但是从驱动器访问数据是一个很慢的过程。因此，数据库供应商已经开发出了处理服务器或子系统（而不是磁盘驱动器）主存储器中数据的方法，这大大提高了速度。但是，在数据库领域中，存内计算的使用仍然基于传统的冯·诺依曼架构和编程模型，只是进行了一定的优化，使其运行速度更快。 


在半导体芯片领域，存内计算具有相同的基本原理，但实现方法是不一样的。有各种使用 DRAM、闪存和新型存储器的存内计算方法，这些方法尤其在许多新的神经网络芯片架构中得到应用。数据在神经网络中进行传递，可能需要访问数以十兆甚至百兆计的权重，但是基本上每个网络层都只能访问一次，然后必须舍弃该权重，并在网络的后续阶段为内存分配不同的权重。这种方式对于存储器的访问量是惊人的。因此，神经网络不同于传统计算系统，它更需要存内计算。 


在基于 GPU 传统芯片架构的 AI 系统中，GPU 需要访问寄存器或共享内存，以读取和存储中间计算结果。如果能把这些内存和处理单元做在一起，就可以大大降低功耗；同样，如果把深度学习加速器 AI 芯片中的 MAC 阵列直接用存储器来实现，就不需要进行矩阵乘积 MAC 与存储器之间的频繁来回访问。 


当前，对逻辑和存储器合并达成「存算一体化」并没有严格定义，关键思想是开发一种新的「以数据为中心」的计算机架构。它的名称有很多种，如称为存内计算（PIM、IMC 或 CIM）、存内逻辑（Logic-in-Memory，LiM）、近内存计算（Near-Memory Computing，NMC）、近数据处理（NDP）等。NMC、NDP 通常指将存储器和逻辑电路合并，放在先进的芯片封装中，而存内计算是将处理单元放在数据存储的内部或附近（即在存储芯片内部、3D 堆叠 DRAM 的逻辑层中、存储控制器中或大型高速缓存内部），以便减少或消除处理单元与存储器之间的数据移动。存储器不再被看作是一种被动的「笨」器件，而是一种即可存储又可进行智能处理的器件。 


一般来说，存内计算可以用于系统中各个层级的存储器里，如片上存储器（SRAM）、片外的 DRAM 或固态硬盘（SSD）等，具体应用到哪一级，则与应用有密切关系。 


备案号:YX01jbkWgwB9w7Lle

