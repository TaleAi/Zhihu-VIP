## 64.保护隐私是一种产品竞争力吗？
知乎的朋友，你好，欢迎收听张鹏科技内参，我是极客公园创始人张鹏。


最近我和一些做产品的人聊过一个很有意思的话题，保护隐私到底是不是一种产品竞争力？


我发现有相当一部分产品人是不那么认可这个观点的。他们承认隐私保护很重要，但是又不认为这是一种用户真正的需求，觉得只要满足最基本的法规就可以了，没有必要在上面去耗费太多的精力。


这种想法其实也很好理解，因为用户在选择一款产品的时候，至少在目前这个阶段，并不会把他的隐私保护能力作为一个很重要的参考指标。


比如你去下载一个 APP 的时候，更多关注的是它能不能满足你的通讯娱乐或者是学习等等方面的需求。你去买一个数码硬件的时候，关注的是它的性能强不强大，质量过不过关。至于他对你的隐私保护是不是到位，可能根本不是你选择时候要考虑的因素，除非是过了一段时间，你用的这个产品出现了隐私泄露的问题，你才会真正关注到他的隐私保护能力。


所以隐私保护对目前中国用户来说，确实处在一个听起来很重要，但是只要不爆发危机，又很容易被人忽视的状态。


不过我和另外一些企业家朋友的看法和前面这些产品人又有所不同。在我们看起来，不管目前隐私保护是不是用户的显性需求，接下来他都一定会慢慢成为产品很重要的竞争力，或者说是一种必不可少的必要条件。


你看最近几年，全球很多的科技公司都爆发了用户信息泄露的事情，用户对他们的信任感在不断降低。在国外 Facebook 就是因为这样的负面消息，一度有人在网络上去号召卸载它。


所以科技公司要想提升用户对自己的信任感，让自己持续发展下去，接下来势必要对用户隐私有更强的保护措施，至少自己在这方面要有更强大的意识。


现在国内很多的科技公司在开发布会的时候，基本上不会花时间去介绍自己在隐私保护上做了哪些努力。但是今年 5 月我和一些企业家朋友们去参加了 Facebook 的 F8 大会以及 Google I/O，已经能够看到美国的科技公司在这方面再做出相应的改变了。


比如在 Facebook 的 F8  大会上，扎克伯格就明确 Facebook 要加大力度去保护用户的隐私，提出了私密互动，加密、更安全的数据存储等等六条原则。同时还推出了让用户可以选择永远禁止 Facebook 收集自身数据的功能，可以说扎克伯格真是用了非常多的时间在去讲过去从来没讲过的问题。


如果说 Facebook 的这些表态和举措，还有一部分原因是因为最近两年持续不断负面新闻让他不得不这么做。Google 则是看到并且顺应了这种加强隐私保护的趋势，在主动求变了。


今年的谷歌 I/O 大会虽然发布了很多内容，但是这里边有一个技术其实特别值得关注，它叫 Federated Learning。翻译成中文就叫做联合学习。通过它能够更好的在机器学习的这种大环境下去保护用户的数据隐私，


这种联合学习的工作原理就是使用存在在你手机等设备上的数据来去训练 AI 模型，以便这些设备能够为你提供更好的个性化服务。


举个例子，之前 Google 就曾经在 Android 自带的输入法 Gboard 上进行过联合学习的测试实验，Gboard 的除了能进行文字输入之外，还有搜索功能，当它显示一个搜索结果的时候，会记录搜索上下文，以及你是否点击了搜索结果。


基于你的历史搜索数据联合学习，就可以持续优化接下来的搜索结果，帮助你更高效地找到需要的答案。


但是在这个过程中用来训练的数据只存储在你的手机上，并不会被发送到云端，这样除非你的手机丢了或者被黑客入侵，否则就不会因为某家公司的服务器被攻破而导致你的隐私的泄露。当然你的个人数据的隐私也会因为这种物理上的隔离不会让这些大平台拿走去私自转换价值。


你看这种情况下，你对自己的隐私数据就有了更多的管控能力，而不是只寄希望一家企业是不是足够上心，是不是足够的价值观正确。


类似于联合学习这种技术背后其实反映了美国科技公司利益中正在慢慢达成的共识，那就是用户自己的原生数据不应该都被中心化的收集，而是应该用所谓的分布式的架构去杜绝隐私信息被大规模泄露，或者是被乱用的风险。


你看目前的惯用做法是把很多的数据存储在一起，只要服务器被黑客攻破，经常就会发生几百万上千万用户的数据同时泄露的事情。但是如果采用联合学习这样的架构，黑客要获得这么多的用户数据几乎是不可能的，他没有办法一台一台手机的去入侵。


当然了就这个观点，我的一个朋友还是跟我争论了一番。我们争论的焦点倒不是在分布式的架构对隐私保护能力上有分歧，而是纯粹从商业的角度来考虑。未来对于用户数据和用户隐私的保护，到底是不是真的能产生商业价值。


我这个企业家朋友就认为其实没必要费那么大劲去做这些所谓的用户数据隐私保护的事情。因为消费者真正买单的时候，现在还不会考虑这些问题，你即便把这件事拿出来说，似乎也形不成一种独特的竞争力。


但是我并不是很认同他的说法，我认为其实在众多的生活经验里，已经印证了人们是愿意为杜绝一些小概率的风险去花更多的钱，付出更多的成本。


比如你去请保洁阿姨，虽然你可能去路边随便找个人价格更便宜，但是你不知道他的人品怎么样，会不会给你的家带来损失。这个时候你可能会情愿多花一些钱通过中介机构去找，因为中介已经为你筛过一遍人，并且已经收集了他们真实的身份，一旦出了问题，中介其实可以在里边去替你追查，这也是对那群人的一种约束。


虽然真正在雇保洁阿姨的时候，你也会很在意是不是足够便宜，但是这种所谓安全带来的小概率事件你依旧也是在意的，它甚至会带来一个中介的商业模式和中介的盈利方式。


所以我相信我们未来一定会看到一个必然的趋势，企业从深层的理解、相信并且投入力量去保护用户的数据和隐私，它不仅仅是一种态度，不仅仅是一种宣传和所谓的政治正确，而一定会成为科技企业在接下来发展过程之中必须要做的一件事，因为如果别人做了你不做，那在这过程中你不但没有竞争力，反而会成为了一个弱点。


虽然在今天用户看起来还没有对科技公司在这方面提出特别高的主动要求，但这也主要是因为我们还没有另外更多的更好的选择。一旦有一些企业开始把这些东西当成竞争力，我相信整个产业的一些规则和标准都会被重写。


在这样的一个趋势下，其实我们也会看到一些新的技术，新的计算架构的变化。这件事情往下再推进，肯定会推动产品的结构，甚至是网络的结构产生不断的调整。


其中一个最明显的变化可能就是边缘计算的崛起。所谓的边缘计算就是在进行数据输入的设备一端去做出的直接的计算。


举个例子，以前要对监控摄像头里的数据进行分析，就要先把不同的摄像头拍摄的视频传到云端的服务器里，然后由服务器进行统一的运算。这个过程中不仅对服务器的性能有很高的要求，也需要很大的数据的传输的带宽和传输的数据量，它会带来成本的提升以及一定的延时，但如果每个摄像头自己都具备这种计算的能力，就不用把视频的数据都传输到一起了，每个摄像头各自把自己拍到的内容进行 AI 的分析，他上传的可能是分析的结果，这样既减少了视频传输的时间，也把计算的任务分配给了更多的中端的设备，整体的计算效率也就提升了。


未来随着物联网的发展会有越来越多的智能设备会进行类似的边缘计算，其实边缘计算这样一个基于网络的计算效率和传输成本降低而诞生的新的计算架构，也会对用户的数据和隐私保护产生正向的作用。


当我们看到未来的这些隐私和数据的保护会成为一种产业的必然发展趋势的时候，而这个趋势又在跟边缘计算相结合。我们看到的其实是整个科技产业里一次对于计算力架构的重新的调整，或者说对于计算力的重新的分配。


我相信这是未来一个非常值得关注的方向，因为这样新的架构一定会带来非常多的新的机遇。


好，今天的张鹏科技内参就到这里，我们下期再见。 

