## 100.更接近生物大脑的 AI 芯片
AI 的终极目标是做到类似生物大脑。生物大脑可以在结构上（作为架构）或功能上（作为行为）被模仿。组成 DNN 的神经元虽然也是模仿生物大脑，但它是一种过于简化的模型。 


一些神经形态学方法试图模仿突触和神经元的脉冲信号，做成类似于生物大脑的芯片。具体来说，就是在电路中再现神经元的细节和机制。但是，细节化的神经元的电路尺寸太大，并不适合半导体芯片集成。因此，目前唯一可以集成的类脑神经网络是脉冲神经网络（SNN，见第 5 章），基于这种网络所实现的芯片属于类脑芯片。 


在这种网络中，突触可以用存储器实现，通常是 SRAM。然而，为了减小面积、降低功耗，很多研究人员正在积极研究用 RRAM、PCM 和 MRAM 等非易失性存储器（NVM）来作为突触器件。使用单个器件而不是复杂的电路实现突触，就可以轻松地扩展集成规模。而神经元行为可以用模拟 CMOS 电路建模，使用生物神经元所需的尽可能多的不同脉冲形状进行信息传递和处理。虽然忆阻器技术目前还未完全成熟，在实际硅片中仅实现了有限的阵列规模，只能适用于小型应用，但是在未来，基于忆阻器的类脑芯片很可能会实现商业应用，并批量生产。 


因此，从 AI 芯片的发展来看，研发的「主战场」必然会从深度学习 AI 芯片转到类脑芯片。神经形态计算和存内计算等技术是很有希望实现 AI 功能的方向。类脑芯片不但使用传统的 CMOS 技术，而且将会用基于忆阻器的新型器件来实现。若干年之后，类脑芯片很可能将在各类 AI 芯片及各种 AI 应用中占据主要地位（见图 17.6）。 


![img](https://pic1.zhimg.com/v2-c4f74534ac37f8e38d22c30c890dc510.webp)

英特尔在 2020 年 3 月宣布的基于 SNN 的 Pohoiki Springs 系统，已经达到了相当高的智力水平。它所模拟的神经元数量和突触数量已经与老鼠的大脑相当。尽管如此，这样的「大脑」仍然无法在自然环境中执行一些简单的任务。这也表明人们对大脑中信息处理的规则还知之甚少，对脑科学和认知科学的研究还只是刚刚开始。只有完全理解了大脑的生物行为，才能建立起真正有效的神经形态计算模型。现在，已有一些公司邀请研究生物脑科学的专家加入 AI 芯片的研究队伍，AI 的研究可能会通过利用大脑模仿来取得更多进展，而对大脑功能的深入了解也将继续激发人们对机器智能的追求。 


表 17.1 和表 17.2 列出了生物大脑与基于硅的类脑芯片的区别。从这两张表可以看出，虽然在有些方面硅芯片可以胜过生物大脑，但是在能效等许多方面，硅芯片与生物大脑还相差很远。这也明确说明了，类脑芯片与生物神经系统之间在实现计算处理的方式上仍然有很大的不同。两者之间的主要区别体现在基本处理组件、系统体系结构、信息编码、配置方法以及构造和校准方法上。 


![img](https://pic3.zhimg.com/v2-9b1de96b41a897af45afc97e1941bf8d.webp)

![img](https://pic1.zhimg.com/v2-485d731a036f1a9ae8e798336f59b1f8.webp)

无论如何，从计算和高能效技术系统实现的角度，类脑芯片还有很多东西要向大脑学习。神经网络的硬件实现不应该是神经系统的精确再现，而仅仅是为了有效地利用现有技术来解决实际问题。在渐渐走向后摩尔定律时代的今天，神经科学、脑科学也正在经历一场革命。借助创新技术，科学家可以对大脑的行为有更深的洞察。基于此，神经科学领域将为新颖的计算解决方案提供长期的灵感来源。将大脑灵感的范围扩展到计算中，不仅将使当前的 AI 算法变得更好，而且将超越大脑的感觉系统，将 AI 扩展到新的应用中。想要充分发挥脑启发计算的潜力，就需要脑科学、计算机科学和神经形态硬件领域之间加强协作并共享知识。 


在类脑芯片（神经形态处理器）的最新研究结果中，已经可以看到未来的巨大潜力。与现有的深度学习技术相比，类脑芯片所需功耗要低几个数量级（25～275mW）。在一些类脑芯片中，各个带存储的内核组成了相互连接（突触）的神经元，从而每个「神经突触」核都有自己的记忆，这就是存内计算的优势。另外，每个核不是以固定的时钟频率运行，而是仅在受到其他计算核的相关活动刺激时才运行，这极大地提高了能效并类似于大脑的工作原理。但是，此技术并不完美，由于硬件架构与传统的架构截然不同，因此并非所有软件工具都可以使用。 


下面再介绍 4 种更接近生物大脑的 AI 芯片原型。虽然这些创新的原型目前还仅仅处于概念阶段，但它们的创新优势和未来的发展潜力已经显露出来。 


#### 带「左脑」和「右脑」的 AI 芯片


发端于 20 世纪 60 年代的 CPU 是基于规则的计算，而 2010 年以后崛起的 AI 计算、量子计算都是基于统计的计算。从应用的角度来看，未来的 AI 系统可能既需要图像识别、图像分类、自然语言处理等非精确的计算，有感知功能，实现与人类的互动；也需要精确的算术运算和精准控制机器的计算，如当前的高级驾驶辅助系统（ADAS）应用。在这两个方面，AI 可能都会胜过人类。有人把这些应用比喻为人脑中的右脑和左脑之分（尽管这种说法至今仍有争议），右脑运作属于感性（艺术、感知、情绪、音乐等），左脑运作属于理性（科学、逻辑、分析、语言等）。如果要做成一种真正类似于人类的智能机器，那就不但需要模仿右脑或模仿左脑，更重要的是要把这两者结合起来。因此，已有模拟左脑和右脑合成的 AI 芯片  [311]  ，即用 CPU、DSP 等模块实现左脑运算，用深度学习加速器模块实现右脑运算，合在一起组成一块 AI 芯片（见图 17.7）。 


![img](https://pic4.zhimg.com/v2-e3b9b7b8435aba29ce0b63b7298d93a1.webp)

同时带「左脑」和「右脑」的想法，未来也将通过光子处理来实现。与电子晶体管不同，让光通过纳米光子处理器中的光学元件不会产生热量。实验证明，如果使用光子处理器，每个矩阵计算使用的能量减少了几个数量级。这种带「左脑」和「右脑」的光子 AI 芯片，在未来的某些应用中可以发挥比电子芯片大得多的作用。 


#### 用细菌实现的扩散忆阻器


尽管 CMOS 及其他新型器件已被用于构建具有复杂电路和低功耗的类脑芯片，但这些芯片并没有被很好地用于模拟时域中的神经和突触行为。美国惠普和一些大学的研究人员曾在 2016 年研制了具有扩散作用的氧化铟银忆阻器，代表了神经形态功能硬件实现方面的进步  [312]  。扩散忆阻器在物理层面上与生物突触和神经元具有内在相似性，这可能使新的计算范式中复制生物神经网络行为变得可行且更加有效。最新的前沿研究是把基于硅的芯片上的开关电路改变为用生物学的蛋白质、细菌等来实现生物大脑的特征，这方面曙光已现。 


在上述扩散忆阻器的基础上，2020 年 4 月，美国马萨诸塞州立大学的一个研究组利用蛋白质纳米线来作为生物导线，制造出了一种新的扩散忆阻器  [313]  。蛋白质纳米线是基于地杆菌（又称土壤细菌）做成的，这种细菌分布在淡水沉积物、有机物或重金属污染的地下水沉积层里（见图 17.8）。它有一种神奇的特性，即可以促进金属还原，改变金属离子的反应性和电子转移性能，从而形成一种可记忆的电阻。这种忆阻器把传统硅芯片使用的 1 V 左右的电源电压降到了 40～100 mV，从而接近生物大脑的工作电压。这是一个重大的概念突破，改变了 AI 芯片最基本的材料和半导体的工作原理，是目前最接近生物大脑的人工神经元和突触之一。如果能够在生物电子学领域进一步探索，让研发走向成熟，未来 AI 芯片将可能与生物大脑直接连接和融合，并颠覆整个 AI 芯片产业。 


![img](https://pic3.zhimg.com/v2-db2d229e613187ff9961087a9f405668.webp)

#### 用自旋电子器件实现的微波神经网络


自旋电子器件的基本原理在本书第 5 章已经作了介绍。一门新的学科「自旋电子学」已在近年得到了蓬勃发展，而带有自旋电子器件的 STT-MRAM 已经走上了产业化的道路。自旋电子器件本身是个振荡器，它能产生很高频率的电磁波（GHz 级）。如果对它的物理特性作深入研究，可以发现它还具有两个很重要的特性：一个是其频率可以通过电流或磁场来调节；另一个是它可以对于一个输入交流信号实现同步（同相）。 


如果把这种自旋电子器件作为神经元，那么神经元之间的连接可以通过自旋电子器件的电磁波接收和发射来实现，这样可以组成一个微波神经网络，即一个微型无线通信网络（见图 17.9）。而学习过程（权重更新）可以通过上述自旋电子器件的两个特性来进行，即调节频率和同步。两个神经元的频率达到同步时，即表明有了强连接的突触。 


![img](https://pic3.zhimg.com/v2-a2bda6f1d469a56806d658fb0a417901.webp)

米格尔·罗梅拉（Miguel Romera）等人已经基于这个思路做了初步的实验  [314]  。他们训练了一个由 4 个自旋力矩纳米振荡器组成的硬件网络，根据自动实时学习规则精细地调整它们的频率，从而识别口语元音。实验表明，较高的识别率源于这些振荡器进行同步的能力。通过将小型动态神经网络赋予振动、同步之类的非线性动态特征，可以使用这种微波神经网络来完成模式分类任务。 


在普通的人工神经网络中，神经元激活函数是静态的，并且通过标准算术运算来实现计算。相比之下，神经形态计算的一个特点是需要包含大脑的动态性质，并希望能够赋予神经网络的每个组件以动态功能。新兴的纳米电子器件可以提供体积极小且节能的非线性自动振荡器，可以模仿生物神经元的周期性脉冲活动，然后使用振荡器之间的动态耦合来完成人工神经元之间的突触通信。由此组成的神经网络又向生物大脑的功能迈进了一步。 


#### 用电化学原理实现模拟计算


受到生物大脑运作非常节能的启发，研究人员正在尝试用模拟器件代替传统晶体管的二进制开关模式。模拟器件可以模仿大脑突触在学习或遗忘过程中变得越来越强或越来越弱的方式。如在本书第 6 章所介绍的，包含两端阻性开关（或忆阻器）的交叉开关阵列可以实现高效节能和快速处理的神经网络。该神经网络的核心组件是阻性开关，其电导率可以用电子电路调节。这种调节模拟了大脑中突触的增强和减弱。 


然而，不管是用 RRAM 还是 PCM，这些两端子器件的性能目前仍远未达到可靠、快速且节能的神经网络训练所需的标准。最新的阻性开关依赖导电丝的形成或依赖相变，这些方法仍然存在稳定性差或能耗高的缺点。因此，需要一种从根本上创新的工作机制来应对这些挑战。 


麻省理工学院的研究人员最近展示了一种新的突触设计，该设计依赖确定性的电荷控制机制，以离子的电化学方式进行电阻的调节，只需要极低的能耗  [315]  。 


在生物大脑中，两个神经元之间的阻性是随着钙、镁或钾离子流过突触膜而增强或变弱的。要实现受这一原理启发的器件，首先需要寻找一种材料，既能与当前的半导体芯片工艺流程兼容，又能够实现高能效的模拟神经网络。这就需要对材料原子和电子行为进行基础研究，熟悉在这种材料中如何实现电阻调节。另外，还需要开发合适的门控电路并优化器件的几何结构。 


该器件利用质子（固态中最小和最快的离子）流入和流出三氧化钨（WO  3  ）的晶格，以模拟方式连续调整其电阻。为了实现有效的门控，需要把两端器件改为三端，即增加一个门控端子，相当于晶体管的栅极。图 17.10 为这个质子电化学突触器件的结构示意图。其中 R 为固态氢储藏层，也用作栅极端子；E 为固态质子所传导的电解质层；A 为有源开关层，作为具有活性物质 WO  3  的传导通道；G 为源极和漏极间通道的电导，由 G=I  d  /V  d  s  计算得出，其中 I  d  是在漏极处测量的电流，V  d  s  是施加在源极和漏极之间的读取偏压；I  g  、V  g  分别为在栅极和源极之间施加的门控电流和门控电压。 


![img](https://pic4.zhimg.com/v2-92cbe5bf9ec341594baf154bc718525e.webp)

通过增加质子和去除质子，通道的电导可以在 7 个数量级范围内调节，从而获得连续的电阻态。质子的插入增加了载流子密度和迁移率，从而增加了 WO  3  的电导。 


这种三端电化学阻性开关机制把质子插在无机材料中作为模仿突触行为的基础，能耗非常低，已经接近生物大脑的能耗等级。另外，它还具有良好的可逆性及编程中的高对称性。 


学术界和产业界的研究重点正在转向如何在神经形态计算系统中引入更复杂行为的概念和技术。最终目的是要获得一种类似于生物的神经形态动态「认知」，能够创造、存储和操纵有关其内在和外在世界的知识，并能够利用这些知识进行经济上有利的行为。如果在自主的 AI 芯片和系统中导入有效的类似于大脑的认知行为，将可提供巨大的经济、技术和社会效益。因此，从生物大脑中全面地提取工程原理、把生物大脑工程化将是未来努力的主要方向，当然也存在巨大的挑战。 


简单地说，当前的 AI 由计算机程序组成，这些程序处理来自环境的输入数据并生成输出数据。深度学习模型基于密集的 MAC 运算，而这种模型与生物大脑的计算模型偏差很大，大脑根本不会进行大量的矢量矩阵乘法。因此，AI 研究人员大多忽略了对脑科学的研究，而只专注于开发 AI 的数学和逻辑方法。本书将在 17.5 节讨论这个问题。 


备案号:YX01jbkWgwB9w7Lle

