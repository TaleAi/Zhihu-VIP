## 41.基于存内计算的 AI 芯片
最近几年来，存内计算已经被用于 AI 芯片的设计，其中包括作为深度学习加速器的 AI 芯片及类脑芯片。存内计算的研究大致可以分成 3 个方向。 


（1）对现有的存储器（如 DRAM）作一些电路改变，如加入一些可以进行逻辑计算的简单电路，执行大规模并行的批量操作。这种方法可以快速设计实施并投入商业应用。初创公司 UPMEM（见第 4 章）已用这种方法做成了产品。 


（2）在 3D 堆叠的存储器中加入逻辑电路，使其能进行存内计算。3D 堆叠存储器现在已经比较成熟，可以利用 3D 堆叠存储技术中的逻辑层来加速重要的数据密集型运算。 


（3）直接使用新型 NVM，一边计算一边存储。这种方法还处于研究的起步阶段，实际使用还有不少挑战。 


#### 改进现有存储芯片来完成存内计算


本节分别介绍在现代计算系统中改进现有存储芯片来启用存内计算的几种新方法。这些方法仅需最小限度地更改存储芯片即可执行简单而强大的通用操作，这些芯片本身的效率很高。 


**1.基于 SRAM 的存内计算方法**


图 7.2 为一种基于 SRAM 的存内计算方法  [121]  ，用于完成 VMM 运算 c=A×b。这种架构基于由 6 个晶体管组成的静态随机存取存储器（6T-SRAM）位单元的阵列，并且包括用于两种工作模式的外围电路。在 SRAM 模式下，通过字线（WL）的数字激活，一次访问一行以读取/写入数据；而在存内计算模式下，使用输入数据激活 WL，一次可以同时访问多行或所有行。这里每个字线数模转换器（WLDAC）施加一个与输入矢量元素相对应的模拟电压值，从而调制位单元电流值。如果将位线（BL、BLB）用作差分信号，那么存储的数据具有将输入矢量元素乘以 +1 或-1 的作用，并且一列中来自所有位单元的电流会累加，产生 BL/BLB 的模拟放电，从而产生矩阵乘法所需的乘积累加操作。这就是说，存内计算并不逐行访问原始位，而是一次访问许多或所有位的计算结果，从而分摊了数据访问的成本。存内计算可以应用于以这种结构集成的任何存储技术和工艺  [122]  。 


![img](https://pic3.zhimg.com/v2-63098c9f8b1ab45f313f07310a74b63c.webp)

**2.基于 DRAM 的存内计算方法**


上述解决方案同样可对 DRAM 来执行批量操作（即对整行 DRAM 单元进行操作），如批量复制、数据初始化和逐位操作。 


对现有存储芯片的最小改动可以调动芯片内部简单而强大的计算能力。这些修改利用了常规存储芯片（如 DRAM）中的现有互连和模拟操作行为，不需要逻辑层，并且通常不需要逻辑处理单元。这样，存储芯片上需要的开销很小，存储单元阵列中的高内部带宽可以被利用。 


在过去的 20 年中，作为主存储器的 DRAM 的存储容量和访问带宽飞速增加，分别扩大了 128 倍和 20 倍，这些改进主要归功于 DRAM 的持续技术进步。与容量和带宽形成鲜明对比的是，DRAM 的时延几乎保持不变，在同一时间范围内仅降低了约 33%。因此，DRAM 的时延仍然是现代计算系统中的关键性能瓶颈。内核数量的增加及数据密集、时延敏感的应用的出现，进一步说明了提供低时延内存访问的重要性。 


2017 年，美国卡耐基梅隆大学的张凯崴（Kevin K. Chang）提出了一种新的 DRAM 设计，称为低成本互连子阵列（Low-Cost Inter-Linked Subarray，LISA）  [123]  ，它可以在 DRAM 芯片中的子阵列之间提供快速且节能的大容量数据移动。它有效地采用了多种新的机制，包括低时延数据复制、减少频繁访问数据的 DRAM 访问时延，以及减少后续访问 DRAM 的时延。 


LISA 技术也包括了对 DRAM 刷新机制的并行化改进，使其性能接近不需要刷新的理想系统。针对 DRAM 制造过程中的不规则性造成的访问速度不一致性，研究人员提出了「可变时延的 DRAM」。这是一种通过将 DRAM 单元分为快慢区域来降低 DRAM 时延的机制，并以低时延访问快速区域，从而大大提高了系统性能。另外，由于电源电压会显著影响 DRAM 的性能、能耗和可靠性，研究人员还提出了一种基于性能模型，动态调整 DRAM 电源电压来提高系统能效的新机制。 


瑞士苏黎世联邦理工学院、美国卡耐基梅隆大学及一些公司的研究人员提出了一种新的存内计算加速器（称为 Ambit），用于加速批量逐位运算  [124]  。批量逐位运算常常应用于图形处理、网络连接、算法加密、网页搜索等领域。 


与现有方法不同，Ambit 使用现有 DRAM 技术的模拟操作来执行批量逐位操作。Ambit 有两个组成部分，第一个组件是 Ambit-AND-OR，它实现了被称为三行激活的新操作，其中存储器控制器同时激活 3 行。三行激活使用电荷共享原理，该原理通过控制第 3 行的初始值来控制 DRAM 阵列的操作，以对两行数据执行逐位与或运算。第二个组件是 Ambit-NOT，它利用了连接到 DRAM 子阵列中每个读出放大器的两个反相器，其中一个反相器的电平代表该单元的逻辑值的反相值，Ambit 在 DRAM 阵列上专门添加了一行以捕获此反相值。这一行的可能实现方式是一排双触点单元（2 个晶体管 +1 个电容器单元），每个单元都连接到读出放大器内的两个反相器（见图 7.3）。 


![img](https://pic1.zhimg.com/v2-ee06203d18ed89faef6b681f118f3e93.webp)

即使存在工艺制造的不一致性，Ambit 仍可以完全使用 DRAM 技术可靠地执行 AND、OR 和 NOT 运算，从而使其功能（即布尔逻辑）完整。 


Ambit 可以实现快速而节能的 DRAM 内数据移动，带来了可观的性能和能耗改进。能进行 7 种常用批量逐位运算（NOT、AND、OR、NAND、NOR、XOR、XNOR）的 Ambit（带 8 个 DRAM 组），与 Intel Skylake 处理器相比，批量逐位运算速度提高了 44 倍；与 DDR3 DRAM 相比，能耗平均可降低到原来的 1/35。相似的基础电路可以在 SRAM 中执行简单的算术运算，而在忆阻器中执行算术和逻辑运算。 


3.用 NOR 闪存技术实现存内计算 


初创公司 Mythic 最近推出了矩阵乘法存储架构，使用 40nm 嵌入式 NOR 闪存技术在内存中执行计算。 


与使用处理器和内存的传统计算不同。Mythic 通过直接在内存阵列中进行处理来尽可能减少数据移动，采用了一种激进的方法，即根本不移动数据，更不用说将数据从 DRAM 移到芯片上了。 


通常，NOR 将数据存储在存储单元阵列中。Mythic 使用 NOR 位单元，但是用模拟电路代替了数字外围电路，在阵列内部进行模拟计算，而阵列具有数字接口。Mythic 后续将会把此架构升级到 28nm 工艺。 


#### 用 3D 堆叠存储技术来完成存内计算


完成存内计算的第二种方法是利用新兴的 3D 堆叠存储技术。在 3D 堆叠存储器中，多层存储器（通常是 DRAM）彼此堆叠，这些层使用垂直硅通孔（TSV）连接到一起。当前的制造工艺技术支持在单个 3D 堆叠存储芯片中放置数千个 TSV。TSV 提供的内部存储器带宽比狭窄的普通存储器通道大得多。商业上可用的 3D 堆叠 DRAM 的例子包括 HBM、Wide I/O、Wide I/O 2 和 HMC 等。 


3D 堆叠的内存芯片都在内部集成了逻辑层。逻辑层通常是芯片的最底层，同样用 TSV 与存储层连接。设计人员可以在逻辑层添加一些存内计算的处理逻辑（如加速器、简单内核、可重构逻辑等），前提是添加的逻辑能满足面积、能量和散热等约束条件。这种处理逻辑也可以被称为 PIM 内核，可以执行部分应用（从单个指令到函数）或整个线程和应用程序，具体取决于体系结构的设计。这种相对简单的 PIM 内核可以避免数据移动，并为各种应用领域带来显著的性能和能效改进  [125]  。 


大规模图形处理和分析正在得到人们越来越多的关注，在从社交网络到机器学习、从数据分析到生物信息学的许多领域中都得到了应用。Tesseract  [121]  是一个把 PIM 内核用于大规模图形处理和分析的例子。它是一种可编程 PIM 加速器，由简单的 PIM 内核组成，这些内核利用 3D 堆叠存储器逻辑层中可用的大内存带宽，每个内核仅在分配给其控制的内存分区上处理数据。另外，有效的通信接口允许 PIM 内核请求对驻留在另一个内核控制的内存分区中的数据进行计算。 


Tesseract 将处理功能移至数据，而不是将数据移至不同的内存分区和内核。经过使用 5 个包含大型图形的最新图形处理工作负载进行综合评估后的结果表明，与传统系统相比，Tesseract 将平均系统性能提高了 13.8 倍，并将平均系统能耗降低了 87%。 


对于 AI 边缘侧的设备来说，能效是头等大事。由于内存结构中的数据移动占了系统所消耗总能量的一大半，因此将处理单元工作负载的关键功能卸载到 PIM 逻辑上可以大大减少数据移动，也就大大降低了功耗。但是，边缘侧的 AI 芯片不但在能效方面敏感，对所需要的芯片面积也极为严格。因此，重要的是要确定哪种 PIM 逻辑既可以最大化能效，又能够以最小的可能面积和成本来实现。 


除了 PIM 技术外，还可以将内存和逻辑芯片集成到先进的芯片封装中，如 2.5D、3D 和扇出，有些人将其称为近内存计算。像 PIM 一样，该想法是使内存和逻辑在系统中更紧密。在 2.5D 中，裸片堆叠在中介层的顶部。中介层包含硅通孔，它充当了芯片和电路板之间的桥梁，可提供更多的 I/O 和带宽。 


如果使用 FPGA 作为 AI 芯片，可以结合使用 HBM。HBM DRAM 裸片彼此堆叠起来，可以实现更多 I/O。例如，三星最新的 HBM2 技术由 8 个 8 GB DRAM 裸片堆叠组成，使用了 5000 个 TSV 进行连接，这样可以实现 307 GB/s 的数据带宽，而传统 DDR4 DRAM 的最大带宽仅为 85.2 GB/s。下一个 HBM 版本称为 HBM3，可实现 512 GB/s 的带宽。重要的是，HMC 等新接口已经包含了初步的存内计算支持，如智能刷新。通过利用这些基本服务，可以进一步开发更复杂的存内计算协议。 


#### 用新型非易失性存储器来完成存内计算


产业界正在研究几种下一代存储器技术，如 FeFET、MRAM、PCM 和 RRAM。所有这些技术都很吸引人，因为它们集 SRAM 的速度、闪存的非易失性及耐用性于一身。所有这几种 NVM 都有望提供能与 DRAM 竞争或接近于 DRAM 的内存访问时延和能耗，使主存储器具有非易失性，同时使每块芯片的存储容量更大。 


但是，由于使用比较新颖的材料来存储信息，新的存储器需要花费更长的开发时间。另外，新型存储技术（如 RRAM 和 MRAM）的跨导或开关比与传统 SRAM 相比要低得多，因此会增加读取电路的功耗和面积。 


由于其非易失性、高存储密度和低功耗，RRAM 被视为比较有前途的 DNN 加速解决方案之一。它的架构模仿神经网络，可以同时进行权重存储和模拟计算（见第 6 章）。利用交叉开关阵列实现神经网络的矩阵运算，就相当于在 NVM 内进行计算。因此，这类新型 NVM 本身就已具备了存内计算的特质。在本地存储和更新权重值，就避免了存储器和处理器之间的数据传输瓶颈。同时，可以通过一次操作替换矩阵乘法和累加两个浮点运算。计算效率和通信都同时得到显著改善。 


使用 NVM 的优点是器件容量大得多，并且通常可以降低单位比特成本，从而降低系统成本。对于数据集大小固定的系统来说，NVM 容量大的另一个好处是可以使系统规模变小。这是一个优点，因为较小的系统具有较低的故障率并能减少软件并行化的障碍。 


RRAM 可以成为从传感、计算、通信、可穿戴电子设备到物联网等应用的数据存储和处理的重要组成部分。与现有的 MAC 运算电路相比，该电路组成所谓的「1T1R」（单晶体管单电阻器）的阵列。在 DNN 中，RRAM 具有执行 MAC 运算的功能，该运算将输入信号与权重相乘并累加，大大减少了对主存储区的访问，同时大大简化了电路。 


利用 RRAM 来完成存内计算还包括算术和逻辑运算、搜索运算和图形处理运算等。在用得最多的算术和逻辑运算方面，也已经涌现出了大量的创新技术，其中一种实现了 XNOR/XOR 逻辑门，能够在忆阻交叉开关阵列中执行 XNOR/XOR 功能  [126]  ，以用于存内计算。这很适合用于许多需要执行算术和信号处理操作的 AI 芯片。 


这个方案使用两个双极性忆阻器（Bipolar Memristor，BM）来存储输入，一个单极性忆阻器（Unipolar Memristor，UM）来存储输出，在 RRAM 的交叉开关阵列中实现 XNOR/XOR 门的设计。为了把门级联起来，将 UM 的值放在 BM 中缓冲，并利用一个忆阻器的功能提供不同的复位（OFF）和设置（ON）阈值电压值。先将 UM 和 BM 分别初始化为 R  O  N  和 R  O  F  F  ；然后为输入忆阻器提供执行电压，仅需这两步即可进行 XNOR 计算。 


而且这种双输入的 XNOR 电路很容易改成三输入的 XOR 电路（见图 7.4），以表现出更好的性能。这个设计减小了面积（忆阻器的数量）、缩短了等待时间（计算步骤数量）并降低了能耗，其局限性在于它既需要 BM 又需要 UM，并且需要使用多个电压。 


![img](https://pic2.zhimg.com/v2-d7b05a7471a12adf0450ef8fcc508f27.webp)

常规的二进制 RRAM 不能有效地表示二值神经网络（BNN）中的正负权重值（+1 和-1），因为二进制 RRAM 器件的高阻态和低阻态值均为正。为此，对 BNN 的实现常使用 XNOR-RRAM 位单元设计。 


**1.世界上第一个通用存内计算芯片**


2019 年 6 月，美国威斯康星大学麦迪逊分校和法国原子能委员会电子与信息技术实验室（CEA-Leti）的研究人员发布了一种名为液态硅（Liquid Silicon）的非易失性可编程的存内计算处理器，该处理器既有通用计算芯片（如 FPGA）的出色可编程性，也有高性能加速器的能效  [127]  。除了一般的计算应用外，它还特别适用于对计算和内存有很高要求的深度学习和大数据应用。 


这种阻变 NVM 芯片不仅可以进行简单的乘积累加运算，而且有许多附加功能。「液态硅」表示这是一种具有高度可编程性的半导体芯片（见图 7.5），其功能可以像液体一样自由变化。 


液态硅器件是通过在商用 130nm 工艺硅 CMOS 上部单片集成 HfO  2  /Ti/TiN RRAM 制成的，可以在 650 mV 的低电压下可靠运行。在 1.2 V 的额定电压下，它执行神经网络推理时的能效达到 60.9 TOPS/W，执行基于内容的相似性搜索（一种关键的大数据应用）时达到 480 GOPS/W，能效比最新的 CMOS 高 3 倍，比最新的 RRAM 深度学习加速器高约 100 倍。 


![img](https://pic2.zhimg.com/v2-b0ac9f6aa3d3c06f2022c710e698b9e4.webp)

具体来说，液态硅是一个由相同分区（Tile）组成的 2D 阵列（见图 7.6）。每个分区均由基于 RRAM 的存储阵列和一组连接节点（图中以圆圈表示）构成。1T1R 单元结构用于构建阵列，单元中的晶体管可以有效抑制路径泄漏以降低功耗，而 RRAM 堆叠在其顶部。连接节点连接相邻的分区，并包含几个关键的模块。 


分区可以灵活配置为 4 种模式，即逻辑运算、搜索、存储和 BNN。它通过使用 RRAM 作为存储器件来更改 1T1R 单元的组合和用法，并更改读出放大器 SA 的角色。由于这些模式的功能分配给了芯片中的所有区域，因此这块芯片可以任意组合各种用于计算、存储、搜索、神经网络的模块，就像提供任何这些功能的 SoC 一样工作。研究人员认为他们开发了「世界上第一个通用存内计算处理器」。 


![img](https://pic3.zhimg.com/v2-ee2a7fc9ac211fd9204bb1e11d8ac9b4.webp)

基于 RRAM 的 PIM 是现今十分热门的研究课题。除了上述的液态硅芯片，还有不少研究人员对这种类型的存内计算提出了改进方案。其中美国杜克大学提出的一个方案是一种混合的 CMOS-RRAM 脉冲非易失性存内计算（Nonvlatile Computing-In-Memory，nvCIM）处理单元  [128]  ，其中包括一个 64 kbit 的 RRAM 宏单元和一个新颖的原位非线性激活（In Situ Nonlinear Activation，ISNA）模块。这里将片上的计算控制器与非线性激活函数集成在一起，以计算卷积或全连接的神经网络。ISNA 通过利用其非线性工作区把模数转换和激活计算合并在一起，从而消除了实现非线性的额外电路的需求，并大大减小了电路面积（见图 7.7）。这种 nvCIM 处理单元的能效达到了 16.9 TOPS/W，最大脉冲频率为 99.24 MHz。 


在许多具有二值权重的神经网络中，需要 4 位或更高的激活精度才能获得高精度。为了实现多位模数转换，上述方案中的 ISNA 包括一个电流放大器（Current Amplifier，CA）和一个整合激发电路（Integrate & Fire Circuit，IFC），如图 7.8 所示。IFC 会以最大频率（99.24 MHz）产生脉冲。这样，ISNA 将 MAC 的结果重新转为时域中的脉冲数字。CA 中的跨导运算放大器 OTA 在 0.3～60 kΩ 的负载范围内（根据 RRAM 特性确定）可以在（300±1.0）mV 处保持稳定的 BL 电压。 


![img](https://pic2.zhimg.com/v2-1abf958878f94f00f1a399ffcb665ba6.webp)

![img](https://pic4.zhimg.com/v2-2be6289aeaa7cd713111ed6466f346c8.webp)

**2.世界上第一个在二维材料柔性基板上制成的 RRAM**


在基于 RRAM 实现的 PIM 和模拟计算的研究热潮中，也有研究人员考虑使用二维材料（详见第 15 章）来制作 RRAM。使用二维材料有很多特殊的优点，如可打印、可弯曲。来自新加坡国立大学和英国剑桥大学石墨烯中心的研究人员最近展示了世界上第一个在使用二维材料的柔性聚酰亚胺基板上做成的可打印 RRAM  [129]  。这种器件可用由多层二硫化钼（MoS  2  ）制成的 3D 打印墨水打印。通过改变电流，可在单个器件内实现易失性电阻切换，也可实现非易失性电阻切换，从而能够实现具有神经形态功能的电子突触，包括短期可塑性和长期可塑性。 


3D 打印可以提供一种非常有吸引力的途径，使器件能够集成到柔性基板上，以进行大规模和低温制造。但是，由于缺少稳定的可打印开关电路介质和可靠的打印过程，因此完全打印的 RRAM 一直还没有成功实现。在前几年，虽然已有报道称在 PET 聚酯上经过溶液处理的 MoO  x  /MoS  2  忆阻开关介质，可与打印的银电极兼容，但 MoS  2  墨水配方方面的进展仍然有很大的不确定性，而这点对于通过 3D 打印技术在柔性基板上实现 MoS  2  RRAM 的大规模单片集成至关重要。 


在上述这项工作中，新加坡国立大学和英国剑桥大学石墨烯中心的研究人员使用气溶胶喷射打印机，通过将银墨水和内部配制的 MoS  2  墨水以垂直堆叠结构交替使用来实现完全打印的二硫化钼 RRAM 阵列，如图 7.9 所示。MoS  2  RRAM 显示了无变形的开关特性，开关电压仅为 0.18 V，有高达 10  7  的开关比，在 1000 次弯曲循环测试下具有很强的挠曲耐久性。 


![img](https://pic3.zhimg.com/v2-0cbd3ed9521e721ba18181b8cd4bda3c.webp)

在使用 PIM 方法的新型 NVM 里，虽然 RRAM 相对比较成熟，但是在可重写次数、芯片容量和单位比特价格方面不如 PCM。但是，PCM 存在「怕热」的弱点，因为 PCM 的相变直接受热量影响。 


由于新型 NVM 日益成熟，PIM 的研究对象已经慢慢转变为使用高密度 NVM 作为其主要内容，称为 nvCIM。而如何把 nvCIM 更好地应用于 AI 芯片，尤其是边缘侧 AI 芯片，是一个很火热的研究课题。 


可以通过以下方式增强边缘侧 AI 处理器的 DNN 操作，并有效使用 NVM  [130]  ：通过将大多数或所有权重存储在 nvCIM 中，来避免多层内存数据访问（NVM-DRAM-SRAM）而导致的时延；减少中间数据访问；将多个 MAC 操作的时延缩短到一个 CIM 周期。 


电路设计和 NVM 器件的许多挑战和限制阻碍了 nvCIM 的实现。到目前为止，仅有一个具有高电阻比的 32×32 CIM RRAM 宏模块  [131]  问世。此外，由于高电阻和低电阻状态下的 1T1R 单元读取电流具有相同的极性，这就使 nvCIM 不能在同一条位线（BL）上同时实现正权重和负权重，而这正是一些 DNN 结构（如 XNOR 网络）所要求的。 


为了降低能耗和硬件成本，陈韦豪等研究人员提出了一种二值输入、三值加权（Binary-Input Ternary-Weighted，BITW）的 DNN 网络结构，如图 7.10 所示  [130]  ，这种结构使用「伪二值」nvCIM 宏模块：nvCIM-P 宏模块存储正权重，而 nvCIM-N 宏模块存储负权重。BITW 网络将三值权重（+1、0 和-1）和改进的二值输入（1 和 0）组合在一起，用于减法（S）、激活（A）和最大池化（MP）。通过引入一些电路，这个 65nm 工艺 nvCIM RRAM 宏模块能够存储 512k 个权重值，并在一个 CIM 周期内执行多达 8k 个 MAC 操作，用于 CNN 和全连接神经网络（FCNN）。 


![img](https://pic3.zhimg.com/v2-9c1869f970c282072fc7310b37ddfe29.webp)

  



备案号:YX01jbkWgwB9w7Lle

