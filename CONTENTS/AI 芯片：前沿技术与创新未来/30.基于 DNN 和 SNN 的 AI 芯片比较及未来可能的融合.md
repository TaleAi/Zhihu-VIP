## 30.基于 DNN 和 SNN 的 AI 芯片比较及未来可能的融合
表 5.1 列出了 DNN（深度学习 AI 芯片）和 SNN（类脑芯片）之间主要特征的区别。如前所述，DNN 中每个计算阶段的等待时间都很长，因为必须在输入图像上完成每个阶段的整个计算才能生成相应的输出。相反，在 SNN 处理中，计算是逐个脉冲执行的，因此，一旦收集到足以证明某个特征存在的脉冲，就会在计算层中生成输出脉冲。这样，输出就是一个脉冲流，它几乎与输入脉冲流同步。因此，在 SNN 中，每个输入脉冲都会用处理硬件几乎实时地进行处理，只要有足够的输入事件允许系统作出决定，就执行分类或识别。另外，就功耗而言，DNN 的功耗取决于处理器的功耗及存储器的读写操作，但 SNN 的功耗很大程度上取决于激发和编码策略的统计信息，如果使用有效的编码策略，由于脉冲的稀疏性，整个系统的功耗会相对低得多。 


与 DNN 相比，SNN 有诸多优势。例如，由于 SNN 中的信号强度不是由脉冲幅度来表示的，而是以恒定幅度的信号的时间宽度或时间间隔表示，幅度小、功耗低。此外，即使信号序列的一部分被噪声破坏，也可以从其余部分解码信息，因此 SNN 具有强大的抗噪能力。SNN 还可以通过少量数据进行学习，并可以进行在线学习和终身学习，以及强大的预测等。 


![img](https://pic2.zhimg.com/v2-baeccc0a9fba096bf798d56cb97cc9e6.webp)

此外，由于典型的 SNN 不会将 MAC 或反向传播作为其功能的一部分，因此它可以在常规 CPU 上完美运行，但在更昂贵且耗电量大的 GPU 上运行则得不到任何好处。由于基于 SNN 的 ASIC 更轻便、功耗更低，因此对于边缘侧应用更具吸引力。现在，DNN 中使用的反向传播方法已被扩展并用于 SNN，但精度不是很高。 


鲁克鲍尔·博多（Rueckauer Bodo）等人讨论了 SNN 和 DNN 对最终分类精度的影响  [88]  。在分类精度方面，一般来说，SNN 要比 DNN 低，但是也有报道把分类精度做得很高的例子。具体来说，用 SNN 来处理时间序列数据的 RNN 和 LSTM 已经能够获得与 DNN 相当的高精度。SNN 的可扩展性不是很好，目前只能做到较小规模的网络，但是可以高效处理一些简单的任务，如 30 像素 ×30 像素的图像识别。 


尽管神经形态模型由于与大脑的紧密联系而在理论上具有吸引力，但相应的 SNN 类脑芯片目前尚无法与基于深度学习模型的硬件加速器在所有特性（面积、时延、功耗、性能、精度等）上竞争。 


通常，与深度学习加速器相比，类脑芯片具有较低的运算能力。很多类脑芯片被设计成以生物学上可行的很低的激发频率（几十赫兹）来运行，而有的为了加快速度，把频率提高至几万赫兹。尽管如此，它们的时钟频率仍然比深度学习加速器中使用的数百兆赫兹低得多。也就是说，由激发频率所确定的频率比由时钟频率确定的频率要低得多。因此，类脑芯片中每次推理的能量（与操作时延和功率的乘积成比例）被证明更高。 


根据目前的开发情况，只有当很大规模的 SNN 在芯片上实现时，SNN 才可能变得比 DNN 更具吸引力，但精度仍然需要提高。 


如前所述，由于 SNN 的时间不连续性，直接使用输入脉冲事件来训练深度 SNN 仍然是一个难题。为了解决这个难题，有人想到将脱机训练的 DNN 转换为 SNN  [89]  。方法是将 LIF 脉冲神经元替换为 DNN（ReLU）神经元，并根据突触权重调整神经元阈值。重要的是，需要将神经元激发阈值设置得足够高，以使每个脉冲神经元都可以非常类似于 DNN 的激活而不会丢失信息。 


充分利用 SNN 和 DNN 各自的优点，把这两种网络结合起来，近年已经有了不少新的研究思路和成果。例如，在处理稀疏信号时 SNN 有更高的能效，因此 SNN 可以用作处理庞大且高度稀疏的输入信号的前端，而 DNN 可以用作后端，以利用其在处理密集和高精度数据方面的优势。SNN 的一些特点也被 DNN 所借鉴，如本书第 3 章介绍的二值网络，在某种意义上类似于 SNN，因为它使用二进制数来携带信息，可以显著提高芯片的能效。 


位于美国硅谷的初创公司 GrAI Matter Labs（GML）最新推出的 GrAL One 芯片，就是把 SNN 和 DNN 这两种网络相结合的最好例子  [90]  。普通的 DNN 要在每一层上处理所有像素或神经元，而这款芯片采用了事件驱动的架构，仅在卷积层上受到事件影响的像素才需要被计算。这种基于事件的卷积计算，大大降低了计算复杂性。如果使用普通的 DNN 来推理，计算每帧图像需要 28.2 MOPS，而用这款芯片进行推理的话，平均只需 1.7 MOPS 就可以完成了，因此功耗非常低。该芯片包含约 20 万个神经元，使用台积电 28nm 工艺，裸片面积为 20 mm  2  。 


在未来，SNN 和 DNN 这两种类型的网络将继续相互融合，将各自的优势组合在一起，催生出更快、更节能的 AI 芯片。 


备案号:YX01jbkWgwB9w7Lle

