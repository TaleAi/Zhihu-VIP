## 31.类脑芯片的例子及最新发展
DNN 型和 SNN 型类脑芯片，可以实现目前只有大型超级计算机才能实现的数百万个并行计算流。但是在类脑芯片上有效地实现神经突触，仍然是一个很大的挑战。 


在过去 10 年中，美国和欧洲的神经形态芯片研发项目有不少属于大型政府资助计划，这些芯片依照以生物学为基础的原理运行，以提高性能并提高能效。例如，其中一些项目直接硬连接到单个电子神经元的许多输入上，一些项目使用诸如生物神经元之类的短异步电压脉冲进行通信。不过，大部分类脑芯片仍在使用传统的数字电路。 


本节将介绍一些最早开发的类脑芯片：动态视觉传感器（Dynamic Vision Sensor，DVS），著名的大型架构 TrueNorth、Neurogrid、BrainScaleS、Loihi 和 SpiNNaker 芯片及 2019 年刚发布的 DYNAP-CNN 芯片。这些芯片采用了不同的特性来模拟 SNN，有的使用数字电路，有的采用了模拟电路。最后，还将介绍使用新的半导体器件和新的神经元模型来实现类脑芯片的新思路。 


（1）动态视觉传感器（DVS）。神经形态工程的研究一开始，就开发出了基于 CMOS 脉冲的视觉传感器。瑞士苏黎世大学神经信息学研究所的托比亚斯·德布吕克（Tobias Delbrück）于 2008 年开发了一种非常成功的脉冲视网膜芯片，称为动态视觉传感器（DVS）。这种脉冲摄像头可以微秒级的精度跟踪运动点，是第一款基于脉冲和脉冲定时的新型图像传感器，不用图像「帧」的概念，而是微秒级「事件驱动」的像素处理。它在改善包括自动驾驶汽车在内的许多应用的性能方面具有巨大潜力。这款芯片现已纳入瑞士 iniVation 的产品线。 


DVS 在很大程度上简化了任务，它把产生异步事件流作为输出，其中每个像素对像素上照明的时间变化进行编码。图 5.6 为用 DVS 追踪网球运动员动态的效果。可以看出，DVS 跟踪运动员的动态「事件」部分，身体运动的精细轨迹细节清晰可见  [91]  ，显示出 DVS 在跟踪人体运动方面相较于传统视频技术的优势。DVS 的优点之一是，它以压缩方式对信息进行编码，仅在照明发生相关变化时才发送脉冲信号，从而从移动物体上消除了场景的静态背景特征；另一个优点是，该对象的所有精确时空信息都可以在 10 微秒级的脉冲时间内以一定精度保存。这些优点让 DVS 成为高速处理和识别系统的理想候选方案。如今，多家公司正在努力开发高分辨率 DVS 相机的商业原型。 


![img](https://pic1.zhimg.com/v2-2b4dea2d29e1ef8365e6457dc602d8b1.webp)

表 5.2 列举了 DVS 技术的诸多优点。 


![img](https://pic3.zhimg.com/v2-1cdcc886275dee2ff62092ae4ee790a1.webp)

（2）IBM 于 2014 年在《科学》杂志上发表了用一种新的「类脑」方法设计的芯片  [92]  ，开始的时候称为 SyNAPSE 类脑芯片，使用基于 SRAM 的 CMOS 电路代替了神经元、轴突和突触的功能。SyNAPSE 具有 256 个神经元和大约 260,000 个突触。输入以并行脉冲信号的形式提供，并且在神经元电路中基于已作为权重加载的突触连接计算出电位，并事先获得了学习的结果。在神经元电路中，当电位超过阈值时，输出脉冲信号会通过轴突连线传输到下一级。此时，以事件驱动的异步方式以极低的功耗执行该芯片中的脉冲信号处理。 


后来，IBM 将 4096 个 SyNAPSE 这样的类脑芯片作为内核并行集成在一个芯片中，制成了被称为 TrueNorth 的第二代数字芯片，目标是实现极低功耗的大型网络处理。它用交叉开关阵列实现，并用时分多路复用对神经元更新。图 5.7 为 TrueNorth 的内核布局和一个内核中脉冲信号路径的概念图。TrueNorth 包含 54 亿个晶体管，相当于 100 万个神经元和 2.56 亿个突触，每个脉冲仅消耗 26 pJ。它能够以低功耗对大规模并行输入执行信号处理，并且达到了仅以 63mW 的功耗执行 400 像素 ×240 像素、30 f/s 图像处理的效果。 


![img](https://pic1.zhimg.com/v2-a4adfb341dfc0ee7e692133eda3427cc.webp)

TrueNorth 类脑芯片标志着芯片设计思路的彻底改变，超越了其他大量模式识别应用中基于神经网络的处理芯片，有望更好地处理一些传统芯片难以胜任的图像和语音识别复杂任务。 


（3）英特尔于 2017 年 9 月宣布了一种专门为 AI 设计的神经形态芯片  [93]  ，在类脑芯片开发方面迈出了重要的一步。这款被称为 Loihi 的芯片具有 1024 个人工神经元或 130,000 个模拟神经元，具有 1.3 亿个可能的突触连接，并结合了脉冲时序相关的突触可塑性模型，是一种针对大规模 SNN 评估的、操作灵活的数字处理器。就功能而言，Loihi 芯片处于用 SNN 模仿生物大脑和深度学习之间的前沿。它将片上学习与各种可实施的学习规则、复杂的神经元模型及多种信息编码协议等集成在一起。如果将这些芯片集成到一个 AI 系统中，它们还可以自己学习新事物（自学习）  [94]  。 


Loihi 具有一个多核网格，包括 128 个神经形态内核、3 个嵌入式 x86 处理器内核及片外通信接口，这些接口在 4 个平面方向上将网格分层扩展到其他芯片。异步片上网络以打包消息的形式在内核之间传输所有通信。片上网络支持用于内核管理和 x86 到 x86 消息传递的写入、读取请求和读取响应消息，用于 SNN 计算的脉冲消息等。 


Loihi 的所有消息类型都可以由主机 CPU 外部提供，也可以由 x86 内核在片上提供，并且这些消息类型可以定向到任何片上内核。可以对消息进行分层封装，以通过二级网络进行片外通信。网格协议支持扩展到 4096 个片上内核，并通过分层寻址支持多达 16,384 块芯片。 


Loihi 的每个神经形态核都实现 1024 个脉冲神经元，这些神经元被分组为构成神经元的树状集。在每个算法时间步长中，它们的状态变量以时分复用和流水线方式进行更新。当神经元的激活超过某个阈值水平时，它将生成一个脉冲消息，该消息将被路由到包含在一定数量的目标核中。英特尔宣称 Loihi 处理器的速度是传统处理器的 1000 倍，能效达 10,000 倍。 


2019 年 6 月，英特尔宣布向研究社区提供一个包含 800 万个神经元的神经形态系统，其中包括 64 个 Loihi 芯片，代号为 Pohoiki Beach。2020 年 3 月，英特尔宣布已完成最新的神经形态系统 Pohoiki Springs，可提供 1 亿个神经元的计算能力。Pohoiki Springs 是一个数据中心机架式系统，是英特尔迄今为止开发的最大的神经形态计算系统。它将 768 个 Loihi 类脑芯片集成到一个具有 5 台标准服务器大小的机箱中。Pohoiki Springs 可以处理某些苛刻的工作负载，具有解决各种计算难题的潜力。 


（4）其他著名的类脑芯片有美国斯坦福大学推出的 NeuroGrid，它使用亚阈值模拟神经电路  [95]  ，可以实时运行，并模拟了一些生物现实机制。2019 年，它已实现为 Braindrop 芯片原型  [96]  ，该芯片将用作 100 万个神经元的 Brain Storm 系统  [97]  的内核。还有德国海德堡大学推出的 BrainScaleS 系统，使用晶圆级的阈值模拟神经电路  [98]  ，其运行速度比生物实时速度快 10,000 倍。它的目标是对具有精确生物学神经行为的大脑规模的神经网络进行仿真。目前它正在升级到 BrainScaleS2。 


英国曼彻斯特大学推出的 SpiNNaker 也是世界著名的类脑芯片，它是一个实时的数字多核系统，于 2011 年完成，负责人是 ARM 处理器的发明人史蒂夫·佛伯（Steve Furber）。该系统在运行于小型嵌入式处理器上的软件中实现神经和突触模型，有较强的可重构性，但它不像其他方法那样节能或快速  [99]  。此后，研究团队一直在尝试将芯片组装到尺寸更大的机器中，于 2018 年底最终实现了使用 100 万块芯片（200 MHz 的 32 位 ARM968）的机器。SpiNNaker2 由德国德累斯顿工业大学和英国曼彻斯特大学开发。它延续了第一代 SpiNNaker 专用于大脑模拟的数字类脑芯片系列，由 1000 万个 ARM 核组成，这些核分布在 10 个服务器机架中的 70,000 块芯片上。芯片使用 22nm FDSOI 工艺。该团队预期 SpiNNaker2 应该能够实时模拟老鼠大脑中的 1 亿个神经元，比传统超级计算机的速度快 1000 倍。 


（5）瑞士苏黎世 aiCTX 的 DYNAP-CNN 芯片是在 2019 年 4 月发布的，或为世界上首款用于实时视觉处理的类脑芯片。DYNAP-CNN 采用 22nm 技术制造，芯片面积为 12 mm  2  ，容纳超过 100 万个脉冲神经元和 400 万个可编程参数，其可扩展架构最适合实现 CNN。它将深度学习的功能和事件驱动的神经形态计算的效率整合到一块芯片中。DYNAP-CNN 是处理基于事件和 DVS 生成的数据的最节能的方式，适用于超低功耗、永远在线的电池供电便携式设备上的实时应用。DYNAP-CNN 的连续计算可实现低于 5 ms 的超低时延，与目前市场上用于实时视觉处理的深度学习解决方案相比，这至少意味着 10 倍的改进。 


（6）总部在澳大利亚悉尼的 Brainchip 于 2019 年 10 月发布了 AkidaNSoC 类脑芯片。这款芯片基于 SNN，用神经元功能和前馈训练方法代替了 CNN 的数学密集型卷积和反向传播训练方法，专门用于低功耗边缘侧 AI 设备。每个 AkidaNSoC 芯片具有 120 万个神经元和 100 亿个突触，其效率是英特尔和 IBM 的类脑芯片的 100 倍。AkidaNSoC 与领先的 CNN 加速器芯片的比较显示出类似的性能提升，并且具有相当的精度。该芯片使用台积电的 28nm 技术，围绕 80 个 NPU 的网格连接阵列构建，但该芯片还集成了脉冲转换器，从而使其能够运行流行的 CNN（如 MobileNet）。转换器可以根据音频、图像、激光雷达、压力、温度和其他传感器数据，以及互联网数据包和多元时间序列数据生成脉冲信号。 


（7）对应于 SNN，也有人提出一种振荡器神经网络（Oscillator Neural Network，ONN），可以通过振荡器同步产生的模拟输出来近似卷积。根据分析，这种网络的运算速度比 DNN 和 SNN 都要快  [100]  。在 ONN 中实现卷积运算的方式是将振荡器耦合到一个公共节点，然后将信号的包络线标识为卷积的度量。在这种方法中，振荡器起着突触的作用，而包络检波器起着平均器的作用，即神经元的作用。不过，振荡器的面积通常较大，因为它包含多个简单门，如 CMOS 环形振荡器中的多个反相器，而平均器和峰值检测器的面积必然更大。 


将来，有可能在这种网络的基础上创建带有纳米级振荡器（压电、磁电等新型器件）的紧凑型神经网络 AI 芯片。这将是一种全新的信息处理系统，可以使用包括磁和电振荡器在内的多种物理振荡器来创建神经网络，不再需要 PE，而是作为独立的神经有机体运行。 


（8）使用光子器件来实现类脑芯片。激光振荡器和放大器中使用的光学增益介质本质上是非线性的，研究人员已经利用这种非线性来实现神经形态计算所需的功能。他们使用半导体光放大器作为整合器，并使用非线性光纤环形镜作为阈值器，开发出光子 LIF 神经元  [101-103]  。类似的方法被用来完成了一个简单的神经形态处理器  [104]  。 


（9）使用电化学器件来实现类脑芯片。基于电化学的器件由于其高精度、线性和对称的电导响应，低开关能量，高可扩展性及适用于 SNN 的内置定时机制，成为有前途的类脑芯片的候选者。在用电化学器件实现的人工突触中，突触权重（通过器件的沟道电导表达）可以通过栅极端进行调节，这决定了沟道中的离子浓度，从而决定了突触权重。该过程通常涉及通过电解质的电化学反应，而通道材料包括二氧化钴锂（LiCoO  2  ）及有机聚合物等。 


（10）使用二维材料来实现类脑芯片。这类材料包含过渡金属二硫族化合物、石墨烯等，它们具有独特且吸引人的光、电、热性能（见第 15 章）。由于这类材料具有丰富的物理机制，如电荷捕获、电阻切换、焦耳加热等，研究人员正在开发基于二维材料的人工突触，利用可调的电子特性来模拟突触可塑性。 


（11）用新的器件建立新的神经元模型。美国麻省理工学院的研究人员首次把约瑟夫森结作为神经元模型的基础，依靠两条耦合的纳米线的固有非线性来产生脉冲行为，并用电路仿真证明了这种新的纳米线神经元可再现生物神经元的多种特征  [105]  。通过利用超导纳米线电感的非线性，研究人员开发了一种可变电感性突触的设计，该设计既可以进行兴奋性控制，又可以进行抑制性控制。当电流流过纳米线超过一个阈值时，纳米线的超导性会突然消失而变成电阻，而电阻的出现就会形成一个瞬时的电压降，即产生脉冲，并且还有不应期的特征。这种突触设计可以支持直接扇出，这是其他超导架构难以实现的功能。演示结果显示，纳米线神经元的性能与功耗都大大优于其他类脑芯片，因此很可能成为低功耗 AI 芯片发展的有希望的候选者。 


备案号:YX01jbkWgwB9w7Lle

