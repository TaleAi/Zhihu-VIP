## 93.量子机器学习与量子神经网络
量子计算使用量子力学现象（如叠加和纠缠）来执行计算。量子计算机不但可以在理论上构建，也可在物理上实现。量子计算和 AI 这两个领域被看作是当前最前沿的科技领域，吸引了大量人力、物力的投入。但过去这两个领域的研究在很大程度上是并行进行、相互独立的。这主要是因为人们还没有看到能真正发挥量子计算潜力的量子计算机，而 AI 的技术目前也还处于早期阶段。 


实际上，量子物理中的一些基础理论可以用传统计算来进行仿真，如果算法设计合理，可以达到意想不到的效果。本书第 10 章已经介绍了受量子原理启发的 AI 芯片，并不需要真实的量子计算机，即可解决非常棘手的大型组合优化问题。 


随着这几年深度学习的迅猛发展，许多研究人员试图把量子计算和机器学习结合起来。深度学习与量子计算的交集称为量子机器学习（Quantum Machine Learning，QML）  [285]  。QML 有两个不同的研究方向：一个是使用机器学习（主要指深度学习）技术来分析量子过程的输出，另一个是受量子结构启发的深度学习算法的设计。 


深度学习的研究人员对量子计算感兴趣，期望量子计算机在深度学习中有用处，主要有两个理由。首先，随着数据量的不断增长，当前深度学习的数据量和计算量正在迅速接近经典计算模式的极限。从这个意义上讲，量子算法为某些类型的问题提供了更快的解决方案。其次，量子学习理论  [286]  已经成为一个专门的研究理论分支，在某些假设下指出了经典和量子在学习上完全不同的实现方法，这意味着那些困难的经典问题有可能从基于量子的计算范式得到明显好处。 


在如何使用量子计算方法来加速深度学习的计算这方面，已经有不少研究成果，包括数据存取和通信、并行架构、线性代数、取样、优化等问题上的应用，把从单个神经元到训练算法的所有组成元素放在所谓的量子神经网络上执行。量子神经网络的第一个研究成果出现在 20 世纪 90 年代  [287]  ，至今已经有许多关于该主题的论文被发表。创建适合量子信息处理的新的深度学习模型是很有前途的研究方向。另外，针对小型量子计算设备的量子神经网络算法开发和实现，将能够发现量子神经网络的实际问题，并可为实际应用的基准测试提供帮助。 


使用量子技术来加速训练神经网络的研究工作主要集中在 RBM 上。RBM  [288]  是生成模型（即允许基于先前观察而生成新的数据的模型），由于它与伊辛模型（见第 10 章）强相关，因此特别容易从量子角度进行研究。研究表明，用 RBM 计算对数似然和取样是困难的，而使用量子技术有助于降低训练成本。 


目前有两种主要的量子技术可以用来训练 RBM。第一种方法基于量子线性代数和量子取样。美国微软的内森·维贝（Nathan Wiebe）等  [289]  开发了两种算法，以基于幅度放大  [290]  和量子吉布斯取样来有效地训练 RBM。这些方法的另一个优点是可以用于训练完整玻尔兹曼机。完整玻尔兹曼机中的神经元对应完整图形的节点（即它们是全连接）。尽管完整玻尔兹曼机与 RBM 相比具有更多的参数，但由于训练的计算成本高，它们在实践中并未使用，并且迄今为止，大型完整玻尔兹曼机的真正潜力尚不清楚。 


训练 RBM 的第二种方法是基于量子退火。量子退火是一种量子计算模型，它对伊辛模型能量函数中的问题进行编码（详见第 10 章）。具体而言，这个方法是利用量子退火产生的自旋结构来绘制吉布斯样本，然后可以用来训练 RBM。量子退火非常适合实现深度量子学习，并且可以在硅芯片上实现和商业化，其中包括用 CMOS 工艺实现的基于量子退火原理的 AI 芯片（见第 10 章）。 


量子玻尔兹曼机  [291]  具有更通用的可调谐的耦合度，能够实现通用量子逻辑，目前正处于设计阶段。 


如何将经典数据编码为量子态是任何量子算法都要考虑的重要部分。一种方法是应用量子随机存取存储器（Quantum Randum Access Memory，QRAM）来存储量子态，并允许以叠加方式进行查询。现在已经有不少关于 QRAM 理论和实践的讨论  [292]  ，但是也有研究人员认为 QRAM 在数据编码为量子态方面不一定有效。在硬件解决方案方面，已经进行了 QRAM 的原理验证演示，但构建大量量子开关阵列是一个难以解决的技术问题。 


也有研究人员把深度强化学习和量子物理结合起来  [293]  。深度强化学习在发现可调谐量子系统的控制序列方面的有效性已经被证明，该可调谐量子系统的时间演化远离其最终平衡，没有任何先验知识。这些简单的考虑及文献中描述的其他分析表明深度学习原理可能植根于量子物理学。 


量子光学这一领域在最近几年有了很大进步，尤其是出现了不少与 CMOS 兼容并基于硅光技术的量子芯片原型。片上硅波导已经被用于构建具有数百个可调干涉仪的线性光学阵列，并且可以使用专用超导量子信息处理器来实现量子近似优化算法。为了构建基于量子光学的神经网络，并最终应用这样的芯片来实现，格雷戈里·施泰因布雷歇尔（Gregory R. Steinbrecher）等人提出了一种量子光学神经网络（QONN），可以将用于 DNN 的许多功能映射到量子光学回路中  [294]  。通过数值模拟和分析，QONN 可以被训练来执行一系列量子信息处理任务，是很有前途的下一代量子处理器架构。 


除了用量子技术构建传统的 DNN 外，也有研究人员构建了量子生成对抗网络（QuGAN），其中数据由量子状态或经典数据组成，并且生成器和鉴别器配备了量子信息处理器  [295]  。当生成器产生与数据相同的统计值时，会出现量子对抗博弈的唯一固定点。由于量子系统本质上是概率性的，因此量子处理比经典更简单。与传统 GAN 相比，QuGAN 可能会展现出指数级的优势。 


量子技术在芯片上的实现，是研究人员多年来追求的目标，也是量子技术领域中最难解决的课题之一。这类专用量子信息处理器将成为未来的量子 AI 芯片，而 QRAM 也将以芯片形式实现（量子芯片见第 15 章）。 


量子计算是一个快速发展的领域，但最重要的问题仍然是：什么时候才会出现真正能够商用的通用量子计算机？虽然近年来由于政府、企业和学术机构的支持，全世界建立量子计算机的努力已取得相当大的进展，但现在人们普遍认为通用量子计算至少在 15 年之后才会真正实用。设计量子计算机的障碍包括确保量子比特在实现算法所需的时间内保持相干性，具备能够实现 0.1% 误差率的量子门，从而可以执行量子纠错，使量子比特实现具有可扩展性，继而允许系统级的有效乘法扩展。 


很多人认为，量子机器学习或量子神经网络是可以提供量子加速的第一个证明。当第一台可实际运行的量子计算机出现之后，AI 将从传统计算机转到量子计算机上，到时将会出现量子人工智能，而这也将可能成为量子计算机的「杀手级」应用。 


备案号:YX01jbkWgwB9w7Lle

