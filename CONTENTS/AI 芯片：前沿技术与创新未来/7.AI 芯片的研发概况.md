## 7.AI 芯片的研发概况
AI 芯片的研发热潮，主要集中在 ASIC 芯片领域。除了各大公司及不断出现的初创公司积极投入之外，大学和研究机构也起到了关键的作用，有的已经有十多年甚至更长时间的技术积累。目前引人注目的来自大公司的 ASIC 芯片，以谷歌的张量处理单元（Tensor Processing Unit，TPU）系列为代表。高通在 2019 年 4 月发布的 Cloud AI 100 系列，也是 AI 芯片性能的一次飞跃。但是，「爆炸式」出现的很多初创 AI 芯片公司，在技术层面也绝不落后于大公司。 


表 1.1 列出了 ASIC 芯片与一些 CPU、GPU 和 FPGA 的参数对比。在「训练」和「推理」两栏中，CPU 的能效和速度为基数，其他都是与 CPU 相比较的倍数。FPGA 因为很少用于训练，因此其训练能效和速度没有数据。ASIC 芯片主要是指深度学习 AI 芯片，虽然与原来的 CPU 和 GPU 相比已经有了巨大进步，但性能和能效方面还有巨大的提升空间。 


![img](https://pic1.zhimg.com/v2-64570146423f63283a73f61d2ade7dc0.webp)

然而，要确定 CPU、GPU、FPGA 和 ASIC 究竟哪一种才是最佳解决方案并非易事，因为这取决于 AI 应用类型和范围、设计约束及所要求的上市时间等。如果上市及应用时间紧，那就只能选择 GPU 或嵌入式 GPU。FPGA 的上市时间相对 ASIC 也较短，设计流程简单，也常用作设计 ASIC 之前的原型。另外，用于云端和边缘侧的芯片要求完全不同，云端服务器里的 AI 芯片需要很大的吞吐量和灵活性，而边缘侧物联网则需要功耗极低、面积很小的 AI 芯片。 


AI 芯片要实现大规模商业化，需要保证芯片能够在极低的功耗和成本条件下达到足够高的性能，能够满足新的 AI 模型和算法的运算需求。虽然目前的硅基 AI 芯片只能算是非常初级的尝试，离生物大脑的性能或能效还有很长的路要走，但是已经形成了很好的发展势头。 


虽然深度学习加速器近年来已成为主流的 AI 芯片类型，但是「AI」不等于「深度学习」。AI 是一个包含广泛方法的领域，其目标是创建具有智能的机器，而深度学习本身作为 AI 的一个子领域，是机器学习领域里众多方法中的一种。 


表 1.2 列出了 AI 芯片研发和产业化概况（截至 2020 年 9 月）。基于深度学习模型的加速器已经相对比较成熟，有的已经得到批量应用；而基于其他算法，包括在原来深度学习模型上进行了大量改动的新模型和新算法的 AI 芯片，大部分还处于实验室研发阶段。接近大脑机制的类脑芯片，最近几年有了很大的进展。量子启发模型比较特殊，已经成功做成了样片，预计在 2020～2022 年上市。总的来说，如果我们把 AI 芯片目前的状况与英特尔 x86 时代进行类比，可以说我们现在正处于 AI 芯片的「286 阶段」，或者说 AI 芯片刚处于 AI 1.0 时代；而以存内计算、模拟计算和新型存储器（如 NVM）为代表的 AI 2.0 时代将会在未来几年到来。 


![img](https://pic1.zhimg.com/v2-9c9f0fa1b34d0d045ed82fb9ab10f1be.webp)

  



备案号:YX01jbkWgwB9w7Lle

