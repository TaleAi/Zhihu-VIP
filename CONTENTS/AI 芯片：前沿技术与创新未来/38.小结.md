## 38.小结
模拟计算曾经是 20 世纪 70 年代高性能计算的主要形式，后来被数字计算机取代，所有的 CPU、GPU 和绝大部分 FPGA 及 ASIC，也都是执行数字计算，使用数字电路来实现。但是，改变这种情况的时机已经成熟。 


这是因为数字计算已经无法以更低的能耗水平提供更强大的计算能力。在 AI 应用中，越来越多的边缘侧计算设备正在出现，这些设备往往是永远在线的，并使用能源十分有限的电池供电，但却要有较强的计算能力。解决这个问题的一种办法就是使用模拟计算。 


一般来说，模拟计算需要用模拟电路（运算放大器、比较器、滤波器等）来实现。在构建神经网络时，有一种办法是以神经元为中心，即创建一个模拟电路，忠实地模仿神经元细胞的行为。不少研究人员作过这方面的尝试，他们再现生物突触或神经元行为的尝试需要 10 个以上晶体管的 CMOS 电路。这样的整合虽然能够忠实再现神经元行为，但受到每个单元需要大量晶体管的限制。然而，使用这种方案，可以用有限数量的神经元开发新的支持 AI 的功能。 


现在，模拟计算已经不再需要由各种模拟电路来实现，而是可用简单的器件代替电路——直接使用新型的模拟器件 NVM。而作为 NVM 中的一种，RRAM 里面的每一个 NVM 单元（交叉开关）已经可以区分出将近 1000 个不同的状态（而数字计算只有 1 和 0 两种状态）。这些状态可以与神经网络的权重值很好地对应，因此可以直接存储各种权重值。通过使 NVM 的电导双向变化，可以实现反向传播算法。NVM 交叉阵列有望大大加速 DNN 训练，并显著降低功耗和面积。对于基于神经形态的类脑芯片来说，SNN 通常使用某些局部更新规则（如 STDP）进行训练，而 NVM 最近已作为 SNN 的突触和神经元器件得到了应用。 


虽然现在已有很多研究团队开发出了第一代含有忆阻器交叉开关阵列的 DNN 芯片及 SNN 芯片，但是目前还处在实验室进行小批量试用的阶段，大规模生产和商用还需要克服许多技术难点。另外，这些 AI 芯片的操作基本上都属于数模混合式，即交叉开关阵列的外围电路仍使用数字电路，这样就需要 ADC 和 DAC，从而增加大量面积、时延和能耗，不但没有充分体现出模拟计算的全部潜力，有时甚至把交叉开关模拟计算的固有好处给淹没了。 


分析表明，在 NVM 应用中，目前所使用的材料会带来很大偏差。发现和设计属性与 AI 算法需求相匹配的新材料，成为使深度学习芯片和类脑芯片获得最佳性能、脱颖而出的关键。 


从目前的研究进展来看，利用基于忆阻器的模拟计算实现神经网络的训练仍有较大难度，但是可以很好地完成推理。虽然模拟计算的推理实现与 GPU 相比，每单位面积的效率要低一些，但是，基于模拟计算的 AI 芯片能够提供低得多的功耗，而这种超低功耗正好可以满足移动终端、物联网、可穿戴设备等的基本需求。因此，这样的芯片即使吞吐量相对较小，也是可以接受的。 


备案号:YX01jbkWgwB9w7Lle

