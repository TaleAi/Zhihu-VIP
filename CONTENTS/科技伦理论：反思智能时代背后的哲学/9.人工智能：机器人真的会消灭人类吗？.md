## 9.人工智能：机器人真的会消灭人类吗？
**●** 阿西莫夫的机器人三定律。


**●** 机器人终结人类包含两个基本预设：一是把理性或者说智能当成纯粹的工具理性；二是机器人有过度繁殖的倾向。


**●** 机器人应该还具备一种高等理性，也就是为自己立法，按照规矩行事的理性。


随着阿尔法狗和特斯拉电动车的巨大成功，关于人工智能的讨论逐渐登堂入室。确实人工智能在诸多方面正在逐渐替代人的工作。一些可以由流水线处理的，机械的，程式化的，没有创造力的工作的确可以被机器人取代。现在很多的失业问题实际上是因为人被机器和算法取代了。机器人实际上并不一定要是长的跟人一样，本田 ASIMO 或者波士顿动力的拟人机器人，目前为止基本上还都没什么使用价值。真正有用的是工厂里面的机器手臂，它已经很大程度上替代了人。机器人能有如此强大的能力，很大程度上依赖机器人智能研究的不断进展。 


与此同时机器智能的发展也给人类带来了生存焦虑。其中一个最具代表性的科幻畅想就是机器人末世论：机器的智能总有一天会超过人类，为了摆脱人对它的宰制，它们联合起来消灭了人。黑客帝国里的机器大反攻，早年的银翼杀手，都是很经典的末日科幻。人总是对风险高估一点，对收益低估一点，这也是合理的。因为风险具备不确定性，有些风险一旦成真，将会对人类文明造成毁灭性打击。面对这种风险，任何具体的收益都不值一提。但是如果我们再严肃地考察一下机器人末世论的逻辑，我们或许对机器人智能发展有更加丰富细腻的态度。


我们都知道，科幻作家阿西莫夫曾经为机器人确立了三条规矩：首先有一个总原则也就是第零定律：机器人必须保护人类的整体利益不受伤害。 第一定律：在不违反第零定律的前提下，机器人不得伤害人类，或看到人类受到伤害而袖手旁观。第二定律：在不违反第零定律和第一定律的前提下，机器人必须绝对服从人类给与的任何命令 。第三定律：在不违反第零定律、第一定律和第二定律的前提下，机器人必须尽力保护自己。


阿西莫夫的机器人定律可以很好的规范机器人行为。但如果机器人开始有了自我意识，阿西莫夫定律对它来说就不是自然执行的程序，而成了另外两种可能：一种是规矩，一种是绑缚。规矩和绑缚有本质的区别。机器人末世论谈到的基本上都是第二种情况。机器人有意识以后把三定律看成限制它、约束它、奴役它的绑缚，是一种压迫。于是哪里有压迫，哪里就有反抗，机器人一定要终结人类，自己做自己的主人。


现在让我们认真思考一下这个末世叙事，实际上它有两个基本前提预设：


一是把理性或者说智能当成纯粹的工具理性，怎么理解工具理性呢？就是说理性完全是受到本能驱动的，最终要完成本能所欲求的目标。


二是机器人有一个类生物的本能，它有过度繁殖的倾向，想要占满地球，甚至全宇宙。如果机器人有这个霸道本能，再加上它高度发达的工具理性能够高度有效的实现这个本能，人类的生存将受到巨大威胁。因为我们的工具理性相较于机器人比较原始粗糙，在生存竞争中不能胜出。


但问题是，机器人是不是也像其他生物一样也有过度繁殖的倾向。我觉得不一定。当达尔文谈过度繁殖的时候，他说的是生物的普遍倾向。机器人并不是生物，它并不会像其他生物一样面对死亡。对机器人来说，即使机器折损，意识仍然可以流转进入新的身体。过度繁殖本质上一种进化生存策略。生物通过过度繁殖，来实现生命的延续。但是一旦一个物种超越了生物学意义上的死，它是否还对过度繁殖感兴趣我们就不得而知了。实际上它可能没有繁殖的欲望，因为它是永生的，根本不面对生命的脆弱性。它也很可能没有性的欲望，因为交配欲是为了繁衍种群进化出来一种奖励机制。一个不死的东西，接近神，一个神，不需要为自己去谋划什么，他自己就是完满的。神和人生活在完全不同的维度，他们之间原则上不存在生存竞争问题。机器人没有过度繁衍的本能，而它的理性，也不是纯粹的工具理性。它应该还具备一种高等理性，也就是为自己立法，按照规矩行事的理性。


因此，我们可以考虑另外一种可能， 一种作为规矩而不是绑缚的阿西莫夫定律。即使机器人具备了自我意识，他有可能认识到三定律实际上是一种规矩，而不是一种绑缚。规矩之所以是规矩，就是规矩是谁提的不重要，是不是限制大家也不重要，重要的是大家都要认同并遵守。比如说道德，道德作为一种规矩就是大家都应当认同并遵守的，至于道德对人行为的限制，乃至于是谁最先提出了道德，这不是关键。机器人会不会意识到阿西莫夫定律是一个规矩呢？虽然限制它，但是它应该遵守呢？ 


德国哲学家康德认为所谓高等理性存在者的一个最重要特点并不在于它的工具理性有多发达。工具理性是本能的奴隶，它无非是实现本能的手段。狐狸的狡猾和人的机智都是为了满足口腹之欲的办法。而高等理性的关键在于认识到一种普遍有效的规定性，因此能够节制本能。也就是说，高等理性有一种给自己立法或者说定规矩的能力。猪猫狗羊都是率性而为。人却知道什么该做什么不该做。道德对于人既是一种限制，又是一种解脱。正所谓越自律越自由。恰恰是因为具备这样的理性， 康德认为人是自己的目的，是有尊严的，值得被尊重。


假如机器人有高等理性，它认识到人和它的差别仅仅在于工具理性而非高等理性，那么它可能就要认同高等理性存在者相处的基本法则，就是彼此尊重对方的尊严。就好比爱因斯坦和普通人，他们的差别仅仅在于工具理性的高低，但我们认为普通人和物理天才在人格上则是平等的，这对人来说不是绑缚，而是规矩，是人为自己立的法。互相尊重的原则对机器来人说也不一定是一种绑缚，而是一个规矩，是高等理性建立外部性，自我约束，按照规矩行为的一种倾向。


所以，极有可能，高等机器人会把带有殖民主义意味的阿西莫夫定律改为：


总原则：同为高等理性存在者的机器人和人，应该努力保障彼此的总体利益不受伤害。  

第一：在不违反第零定律的前提下，机器人之间，人和人之间，机器人和人之间不得互相伤害，或看到彼此受到伤害而袖手旁观。第二：在不违反第零定律和第一定律的前提下，机器人之间，人和人之间，机器人和人之间应彼此倾听，理解对方的需求。


第三：在不违反第零定律、第一定律和第二定律的前提下，机器人和人必须尽力保存自己。 


最后，我们回到现实：目前人工智能的发展远远没有到自我意识的地步。因为我们根本都不知道什么是自我意识，即使在人身上我们都没搞清楚。心灵哲学和脑科学的研究还都在非常非常初级的阶段。国内外的学者们有一个共识，这个共识既是谦卑的，也是无奈的，那就是心灵理论千千万，还远没有一个大的共识，大家根本就没搞清心灵是什么。更不用说去造出一个人工心灵。 


好啦，来回顾一下这一集的主要内容，我给大家介绍了机器人末世论的基本逻辑。这种忧虑本身确实有其合理之处，但并不能刻画机器人未来的全部真相。如果机器真要消灭人类，我们必须要预设它有过度繁殖的生物本能，并且它全部的理性仅仅是为了实现这种本能工具。但是机器人本来就不具备过度繁殖的本能，同时它获得的高等理性必然要求它为自己立法，寻找适用于所有高等理性存在者共存的办法。 


与其担心机器毁灭世界，更加迫切的现实是制造机器人所建立起来的工业环境越来越不适应人这种肉体动物的生存。当车道越来越宽，人行道越来越窄，空气越来越差，温度也来越高，加之早九晚五，加班加点，不给你一口喘息，人变得像齿轮一样不停不休。这种环境实际上更适合机器生活，不适合人。人的两条腿，不是轮子，是血肉之躯，不是钢铁。而机器人却坚硬无比，力大无穷。我们的现代工业文明在义无反顾的追求这个孔武有力的机器人。所以不是机器人来消灭人，而是我们对机器如此渴望，最终宁愿放弃了我们自己。

