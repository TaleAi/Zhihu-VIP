## 56.中国人口论证：阿凡达只存在于科幻电影里
**导语**


本集所要讲的中国人口论证，也是对于机器功能主义的一个反驳。这一论证有意思的地方在于，它是让每个中国人来扮演一个神经元，看看会发生什么。本集将包含以下内容：1. 中国人口论证与中文屋论证的异同；2. 中国人口论证是如何展开的；3. 早期版本——莱布尼茨之磨坊论证；4. 对于人类智慧进行建模的法则。


  



各位听友大家好，我是徐英瑾，非常开心能够继续和大家来讨论用得上的哲学这个话题。


上一次节目我们主要讨论的是中文屋思想实验，提出者是美国哲学家约翰·塞尔。约翰·塞尔他提出中文屋思想实验的一个动机是，他要证明功能主义，尤其是机器功能主义，对于心智的描述方案是错的。


实际上，约翰·塞尔并不是唯一一个对功能主义提出批评的哲学家，对功能主义提出的批评非常多，今天我们要讲的另外一个批评，是由美国哲学家内德·布洛克在 1978 年提出的一个论证，这个论证的名字叫中国人口论证。


#### **两种批判的同与不同**


中国人口论证也是用来攻击对于心灵的功能主义描述的，它和约翰·塞尔的中文屋论证之间有什么差别呢？


两者之间有点差别。约翰·塞尔攻击的机器功能主义是和符号 AI 联系在一起的。什么叫符号 AI 呢？这是人工智能当中一个比较老派的路数，就是一个计算机系统，它把一个领域里面的知识全部装在它的知识库里面，按照一些逻辑学的规则或者概率学的规则，从里面引申出一些结论，这些结论本身会对人工智能系统产生一些指导作用，告诉这个系统接下来要干什么。


我举一个例子，这个例子虽然有点恐怖，但是能够说明这个符号 AI 是怎么运作的。我们都知道，前不久波音 737 Max-8 这个版本的飞机是接连出现了严重空难，最近的一次空难是埃塞俄比亚航空的。为什么会出现这个空难呢？因为它本身是由一个符号 AI 的系统来控制机器的运作。


这个机载的 AI 系统当中有一条公理，它的内容是这样，如果飞机把头抬得太高了，飞机的人工智能系统得自动地把机头压低，防止失速。


好，那次空难是怎么产生的？就是传感器本身发生了一个错误，实际上飞机的机头并没有上扬，它却误报机头上扬了，结果飞机的 AI 系统就把飞机的机头往下压。它本来是以为这样一压就水平了，但是因为本来的上扬的信息是错的，所以它就把飞机改为俯冲状态了。飞行员没有办法和 AI 抗衡，最后就导致坠机了，就造成了一个非常恐怖的灾难。


我是通过这个案例告诉大家，符号 AI 它是怎么运作的，它有一些像规则一样的东西，通过逻辑推导就硬邦邦地在推了。


约翰·塞尔的中文屋论证里面它也是有很多规则的，这个规则是装在什么东西里面呢？是装在规则书里面的。面对一些中文的输入，在这个规则书的帮助下，可以让屋中的约翰·塞尔知道怎样的输出应该被递送到外面去，这也是一句句写成规则的。


但是，这并不是做 AI 的唯一方式，也不是实现机器功能主义的唯一方式，机器功能主义它也可以不从规则入手，它可以从一些更底层的活动入手，比如神经元的活动，我们也可以用机器来模拟神经元的活动。


我们都知道，我们的大脑是由大量神经元所组成的，神经元的数量是相当相当多的，不同的文献有不同的说法，有些文献说是 860 亿个，可能有些数量比它更多一点，但是 860 亿个就吓死人了。每一个神经元，实际上它的基本构造是这样的，它是由树突、轴突、髓鞘和细胞核构成。站在计算机的立场上看，每一个小小的神经元都是个小计算机，860 亿个神经元构成了一个超级计算机。


每一个作为超小型计算机的神经元，它是怎么运作的呢？它有两个很重要的输入和输出设备。它的输入设备是什么呢？就是所谓的树突。树突它从其他的神经元接收信号。


它的一个输出设备是什么呢？就是轴突。也就是说，它从其他的神经元那里获得了各种信号以后，它再进行一个信息加工，决定这个信号要不要发送出去。它决定要发送出去了以后，就会通过轴突以电脉冲的形式，一种生物电的形式，传给其他的神经元。


那么，其他的神经元也会从前一个神经元那里获得信息，同时它也可能从很多别的神经元那里获得信息，汇总以后再来决定，我要不要发送出去。


我就举一个例子，比如很多同学都坐在幼儿园里面，每个人都扮演一个神经元，我们要投票谁是我们爱卫生的小标兵。


大家就要选小芳了，但是一些人赞成小芳，一些人不赞成小芳，结果很多小朋友就喊了，有人喊小芳不错，有人说我们反对小芳。这时候你大概听到了十个声音，你听到这十个不同的声音以后，你可以决定沉默不语，也可以决定站起来，给出一个你心目中认为正确的答案。很有可能你是什么答案也没有给出，因为你会觉得这件事对你的刺激不够大，或者这些信息本身还不够完整等等。


所以，我们其实是可以在整个人类的、更高的层面上重演神经元的这样一个运作的。


在人工智能领域里面真的就是有一个专门的学派，试图把大脑当中神经元之间连接的方式，用人工智能的方式做出来，这个流派就叫人工神经元网络。


因为它是人工的，所以它显然不是真的要把一个脑子做出来，它还是在计算机的数学模型里面来体现的，它不会牵涉到人的大脑中存在的一些具体的化学物质，比如多巴胺，比如乙酰胆碱，它不会牵涉到这些东西，它仍然是硅基的。


但它的原理确实和神经元网络是非常类似的，每一个计算单元都会从别的计算单元里面获取信息，它获取信息以后会决定我应该不应该把这个信息传送到下面一个单元里面去，通过这些计算单元之间复杂的联系，最后它构成了一个巨型的网络，好像就有智能了。


现在的这些巨型的网络，因为它的层次是非常多的，以至于在文献里面我们已经给它发明了一个新的词，这个词叫深度学习。也就是说，人工神经元网络当中的学习的层次和网络的结构非常复杂， 所以它可能会表现出一些更加优异的性能。


沿着这个思路做下去，有些搞人工智能的人就指出了，即使是深度学习的人工神经元网络，对于真实大脑的模拟仍然是非常片面的，它仍然是严重低估了真实的生物脑的复杂性，所以，就有一种更加疯狂的想法，就是要做类脑人工智能。


类脑人工智能，就是要高度地把人工智能和大脑完全结合在一起，根据大脑真实的生物学结构和神经回路，全面系统地在人工智能的层面上重构出一个电子脑。


听听都非常科幻，但是在科幻电影里面这已经实现了。比如在电影《阿凡达》里面，对于海军陆战队员杰克的大脑的重建，实际上已经预设了当时的科技，能够把人类大脑的 860 亿个神经元之间的复杂权重和其他相关的参数，全部由一个超级数学模型体现出来，这是非常疯狂的一个想法。


内德·布洛克采取了一个和约翰·塞尔类似的思路，虽然约翰·塞尔他攻击的是传统的符号 AI，而内德·布洛克攻击的是神经元网络的 AI，但是他们采取的一个根本的哲学思路是一样的，他们预设了我们现在的科学技术手段，已经能够把我要批评的这个技术路数所要做的事情完全实现了，但即使在这样的情况下，你们做出来的东西仍然是不具有真正的智能的，这就是他们大致的一个论证。


#### **中国人口论证：强人工智能是不存在的**


内德·布洛克他是怎么样论证的？和约翰·塞尔一样，他还是给出了一个思想实验。


这个思想实验是这样的，他设想有 10 亿个中国人——因为在 1978 年，有 10 亿个中国人——他让 10 亿个中国人来扮演人类所有大脑中的神经元的角色。


当然，这在数学上是有问题的，人类的神经细胞是 860 亿个，不但中国人是没有办法扮演所有的神经元的，地球人都不能满足，因为地球人现在也就是 860 亿的一个零头，所以，他这里是犯了一个不识数的错误了，但是我们在这里不去纠结。


他就假设，每个中国人都扮演一个神经元的功能角色——请注意，不是扮演神经元的生物学角色，只是在功能上模拟它，也就是说在一个数学模型里面模拟它，也就是彼此之间给出很多的信号——在 10 亿个群众演员的头顶上有一个信号灯，这个信号灯上面的文字，可以让群众演员知道他们要干什么。


信号灯就显示说：所有在湖南省的群众演员，现在你们做的事情就是打下面的号码。他们就打下面号码，他们也不知道这号码什么意思。然后，所有在上海的群众演员手机都响了，什么情况？然后又看到信号灯有个指示：所有上海的群众演员，看到你们的电话铃响了，全部不要理，这是骚扰电话。


每个人都不知道他们在干什么，就像你在执行一个复杂的认知任务的时候，每个神经元都不知道它在干什么。但是非常奇怪的是，也许在一个很宏观的立场上，你如果站在一个上帝的角度来看这 10 亿个群众演员做的事情，你就会说了，他在回忆一件事情，这个超级的脑子在回忆他的初恋情人。


好，那么内德·布洛克做的这个思想实验的目的是什么？他说，如果机器功能主义是对的，那么我就能够找 10 亿个群众演员来扮演人类大脑的这个功能，但是我要问一个问题，即使 10 亿个的群众演员他们的表演都非常认真，没有出任何的差错，这样一个由群众演员构成的大脑，它是不是具有一个主观的意识？它是不是有感觉？


内德·布洛克说，显然是没有的，你在哪里能够看到感觉？你没有，你看到都是机械的运作。然后他再反问了一句，有感觉、有意识这件事本身，是不是智能的一个本质性规定？也就是说，没有这个东西，就没有真正的智能了？


比如当年一个叫深蓝的电脑，打败了卡斯帕罗夫，俄罗斯的国际象棋高手。但问题是，卡斯帕罗夫被那个深蓝打败以后，他很可能就会产生一种沮丧的心情，而且他知道自己在沮丧，但是机器人或者一个程序，它能感觉到自己很开心吗？它不会，它没有这种我们人才有的主观的感受。


同样的道理，10 亿个群众演员他们玩来玩去，到最后也没有能够模拟出这个宏观的感受是什么，所以，人工智能所做的所有模拟，仍然不能够把人类智慧的方方面面都加以穷尽，所以强人工智能是不成立的。


#### **早期版本：莱布尼茨之磨坊论证**


美国哲学家丹尼尔·丹尼特，很不喜欢内德·布洛克的这个论证，他就反问内德·布洛克一个很简单的问题：你又不是由群众演员构成的一个大脑，你怎么知道这个大脑没有主观的感受呢？它有，它不一定告诉你，那个大脑自己感受到了，对不对？就类似于「子非鱼，安知鱼之乐」。


丹尼尔·丹尼特就进一步指出，内德·布洛克的思想实验看似非常前沿尖端，但实际上是一个非常老套的东西，历史上早就有一个论证，其精神是和中国人口论证很接近的，是谁提出来的呢？就是我们前面提到过的德国大哲学家莱布尼茨。


莱布尼茨我们已经说过了，他的世界观是什么？整个世界中到处弥漫着精灵，他把这些精灵称之为单子。所以在骨子里，他基本上认为灵魂这个东西是弥漫在世界的各个角落的，但是他又承认了能够被称之为灵魂的和智慧的东西是高级单子，比如一块木头，它里面有的那个精神含量是相当低的，所以不配叫灵魂。


现在有一个问题，灵魂和大脑之间的关系是什么？它是不是实现于我们的大脑呢？


莱布尼茨不是这么想的，因为他不是个物理主义者，他是个唯心主义者。他认为大脑本身它如果有的话，也只有作为物质才配有的那种低级的灵性，而不配具有人类的灵魂所具有的高级灵性。他为了说明这一点，就给出了一个论证，叫磨坊论证，是内德·布洛克的中国人口论证的前身。


他就假设，把一个人脑子放大到磨坊那么大，以至于我可以走进去，我可以走进去以后就可以看到他脑子里的各种各样的化学反应和生物反应了，看得都很清楚。莱布尼茨就问了，我对大脑进行了如此认真的研究以后，我发现了主观感受吗？我发现了意识吗？


我没有发现。所以，如果说灵魂中的核心部分是主观感受和意识的话，既然它不能够通过对于人类大脑的神经学研究来发现，这就足以证明你不能从神经学和物理主义的角度，来阐发人类大脑灵魂的本质是什么，所以唯物主义是错的，所以我的单子论是对的。


丹尼特也以类似的口吻嘲笑莱布尼茨，说，你怎么能够仅仅因为你没有看到一件事情发生，这件事情就不发生了？


我随便举个例子，你们知道在天文学上有一个概念，叫暗物质。暗物质是一个很神秘的概念，总而言之就是你看不到，但它客观上是存在的。所以丹尼特的思路也就是这样了，你能够因为你自己的眼睛看不到暗物质，就说暗物质不存在吗？这实在太扯淡了，我们有很多东西肉眼都看不到的。


所以，上面所讲的这两个思想实验，无论是布洛克的思想实验，还是莱布尼茨的思想实验，他们都过于急躁地依赖于哲学家的一个主观的常识，这个常识就是，我没有看到这个东西，所以它是不存在的。而这个论证是出现了很大的问题，因为在科学领域中我们不能够直接看到但存在的事情是很多很多的，可以说是不胜枚举。


#### **想要对人类心智进行建模，要做减法**


讲到这一步，可能大家就问了，我本人对于把神经元网络、深度学习或者是类脑人工智能，与机器功能主义相互结合的思路，是怎么看的？


从哲学上讲，我认为这条思路是走得通的，但是我对这条思路有经验上的忧虑，就是科学层面的忧虑，不是哲学层面的忧虑。因为人类的大脑过于复杂，我已经说过了，大脑是由 860 亿个神经元构成的，那实在是太复杂了，你真的不知道其中哪些事是重要的、哪些事不重要，而现有的科技要把这么复杂的人类大脑进行数学建模，看上去这个工作量是遥遥无期的。


我始终认为，对于这样一个人类智慧的建模要采取一个减法，就是想办法能够从这些复杂的生物学现象里面，找到一个规律性和本质性的东西。


怎么做减法？可能有两个路数。一个路数是请心理学帮忙，因为心理学所发现的那些规律，或者心理学所提出那些模型，总的来说比较精简，比较容易在计算机建模的平台上加以实现。


另外的一个路径就是，不要老盯着我们人类的大脑，可以盯一些非常原始的大脑，甚至是像苍蝇的大脑、果蝇的大脑、蜜蜂的大脑，这样的研究比较容易操作，因为它们大脑的神经元的数量相对有限。


当然了，要对这么小的昆虫脑进行研究，也许对我们现有的科研手段构成了一定的限制。比如举个例子，你在猴子和人的头皮上可以贴很多电极，你在苍蝇的头上贴电极，整个电极都要比苍蝇大，你怎么贴？这可能对微观实验工具的性能就提出一个更高的要求了。


关于这个话题我不想多扯了，因为我们这档次节目，题目叫「用得上的哲学」，不是「用得上的神经科学」，这些问题应该交给神经科学家去讨论，我在这里就偶尔吼两嗓子，客个串，走走场子，仅此而已。

