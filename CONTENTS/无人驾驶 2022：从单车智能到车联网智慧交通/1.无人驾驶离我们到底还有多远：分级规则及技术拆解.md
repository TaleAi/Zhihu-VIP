## 1.无人驾驶离我们到底还有多远：分级规则及技术拆解
「无人驾驶」一直是一个充满矛盾的高新技术。


在大众眼里，它看起来是那么的遥不可及，可同时又仿佛近在咫尺。英国《卫报》2015 年预测：到 2020 年，你将成为一个「永久后座司机」。马斯克也曾放言，特斯拉将在 2018 年达成这一目标，如果不成，2020 年也终会实现。


但现在已是 2021 年，2020 年我们等来了许多出乎意料的灾难，却没有等来众心所向的无人驾驶。车水马龙的道路上依旧很难见到自动驾驶的踪影，寻常大众也根本没有机会体验坐在无人车里到底是什么感觉。


然而不可否认的是，当今的智能驾驶技术与十年前相比已是判若云泥。智能语音交互、自动保持车道和自动变道，早已飞入寻常百姓家，更高端的自动泊车也已经是高端车型的标配了。就连前段时间的百度世界 2020 大会上，百度 Apollo 也为我们展示了短距离的完全无人驾驶技术，并辅以 5G 云代驾。这一刻，自动驾驶仿佛又是近在咫尺。


**那么，无人驾驶离我们到底还有多远？**


要回答这个问题，就必须先了解**无人驾驶的分级规则**。


**一、无人驾驶的等级（L0-L5）**
====================


无人驾驶的分级是由 SAE（美国汽车工程师学会）定义的从 0 到 5 的无人驾驶等级，即非自动化、辅助驾驶、半自动化，L3 的有条件自动化，L4 高度自动化，直到 L5 的完全自动化。具体定义如下：


* L0：**人工驾驶**，驾驶员完全掌控车辆。
* L1：**辅助驾驶**，驾驶员仍为主要掌控者，系统只会在特定的情况下介入。常见的防锁死刹车系统（ABS）与动态稳定系统（ESC）都属于这个级别的功能，一般在驾驶员驾驶不慎时介入。
* L2：**部分自动驾驶**，驾驶系统可以完成某些任务，但驾驶员仍然需要实时监控环境。与 L1 类似，系统在特定情况下界入，但功能更加多元与高级。常见的功能有自动紧急煞停（AEB）主动式巡航控制（ACC）、车道偏移辅助（LKA）。
* L3：**有条件自动化驾驶，**在某些特定情况下，驾驶系统可以完全掌控驾车，暂时解放驾驶员。驾驶员可以在适当的时刻查看手机，但不可已进入深度休息状态，**以便在紧急时接手**。Audi 推出的 Traffic Jam Pilot 就属于这个级别，允许用户在堵车时开启无人驾驶模式，然而一旦交通顺畅或需要下高速路口，用户必须重新接管。
* L4：**高度自动化，** 自动驾驶不再需要用户的紧急应答，可以完全接替用户，用户可以进入完全放松状态。然而这个系统的启动是要满足一定条件，比如天气需晴朗，或者只在高速适用，但和 L3 相比，它的限制条件已大大减少。
* L5：**完全自动化，**自动驾驶的终极形态，系统在任何情况下都可以安全地掌控汽车，不在再需要用户的介入。

那么我们现在的无人驾驶技术到底到了哪个等级呢？


答案有些令人失望。虽然有许多公司在全力研究 L4 及其以上的技术，**但是市面上量产的智能驾驶车辆大多只达到了 L2 级别，部分拥有 L3 功能，但由于限制太多，**仍然不成熟。


所以自动驾驶到底难在哪里，我们到底还要多久才能见到 L4 的商用汽车？


要想回答这个问题，就必须先了解无人驾驶系统都由哪些模块组成。


**二、 藏在无人驾驶系统背后的人工智能与优化算法**
===========================


![img](https://pic4.zhimg.com/v2-871d3906e8f73ae3001201adb4487625.webp)

正如人类需要用双眼、鼻子、耳朵感知周围的环境一样， 无人驾驶系统通过摄像头、雷达、激光雷达等感知车辆周围环境和状态，作为后续决策的依据。


![img](https://pic1.zhimg.com/v2-6dcf85cbecba78813baf5db2f4c60185.webp)

摄像头等硬件设备只是为无人驾驶系统提供了一个信息丰富的输入，而要让它们从中提取关键信息，真正地感知世界，则需要用到**人工智能与深度学习算法**。在上图中，AI 算法实时处理着摄像头拍摄的一帧帧图片，并把图片中的人、汽车通过方框准确定位**（AI 术语：目标检测）**，这样系统就知道前方有哪些东西以及它们在什么方位，作为之后决策的先决条件。


![img](https://pic2.zhimg.com/v2-ae03f54147fcec45525cfde446373169.webp)

车道线检测（AI 术语）是系统将图片中的车道线检测出，方便汽车行驶在车道线中央。


![img](https://pic2.zhimg.com/v2-4c54a33e0efff283e8254beed3e602ce.webp)

语义分割（AI 术语）则是系统将图片每个像素精确分类，这样例如就可以精确的知道图片中哪些像素点是可以行驶的路段，哪些是建筑物和障碍物。此外，语义分割还可以用来佐证目标检测推测的类别是否正确，例如目标检测识别出方框里面是行人，但是语义分割判断方框中 90% 的像素点是汽车，那么这个时候，目标检测很有可能判断错误了。


![img](https://pic4.zhimg.com/v2-8fc085faa80d698e226ac6b9a18e9f3a.webp)

当我们人类走在自己熟悉的街道时，脑海里往往会自然而然产生一张地图，上面有你目前的定位以及目的地的位置，这样我们人类才清楚下一步往哪走。


无独有偶，无人驾驶也只有在精准定位后，才可以规划路线。为了能让系统更好地定位，各大公司往往都要配备高精地图。


![img](https://pic1.zhimg.com/v2-33a6eaf1c42fa1fccf1109c1c64e0e85.webp)

与常规导航地图不同，高精地图含有更多、更准确的道路信息，它不仅标有车道线的位置，连交通信号灯的位置、斑马线、指示牌、甚至路边电线杆的位置都包含在其中。无人汽车除了配备更高精度的 GPS 外，还会通过计算机视觉、激光雷达的几何和深度学习算法，配合标识物实现精确定位。比如系统通过物体检测识别到了左前方三十米有一根电线杆，然后它以此对照高精地图该电线杆的位置，从而准确知道自己的位置。


![img](https://pic3.zhimg.com/v2-8ebf898122006e00c70ee180ec901b17.webp)

当系统借助精准定位认清自己的位置，通过感知识别周围的环境，经过高精地图获取接下来路段的详细信息，就能通过算法计算出未来几秒-十几秒的精确轨迹了，它通常是满足约束条件下的最优行驶轨迹。


这个行驶轨迹在生成过程中是需要预测周围物体移动轨迹，并以此做出决策的。


![img](https://pic2.zhimg.com/v2-0ef7e7f52ae24f7188c91c1a5cecbd76.webp)

如上图所示，假设我们在路口想要右拐，对面马路不停有车辆开过，系统首先需要预测对面车辆的行驶轨迹，并以此做出并道还是减速并停下的决策。


如果系统决策 1 秒后并道，则必须几乎同时精确地规划出一条右拐弯轨迹（加以验证），这条轨迹（绿色实线）需要满足保持在车道内、规避其他车辆等约束。


![img](https://pic2.zhimg.com/v2-afd4e37c6d077af32c55ae16b377f2c7.webp)

前面讲的三个模块虽然听起来科技感十足，但最终，落在无人车上的指令是由控制系统产生的。


控制系统通过各种算法（例如最常见的 PID 算法）结合汽车当前的车速、车头方向、规划的行驶轨迹以及目标速度产生三个指令：踩油门、刹车、转向。


前置的所有努力都是为了在这三个指令上做出最好的选择，由此可见控制算法的重要性。


**三、驱动无人驾驶前行的燃料——亿万级别的数据**
==========================


现在我们了解了自动驾驶主要由哪些模块组成，那么是什么阻挡着无人汽车的进一步普及？


关键答案之一就是**昂贵的数据。**


大数据的人工智能的时代，数据就是人工智能的燃料，算法也需要大量的已标注数据进行训练，才会变得越来越智能。


任凭人工智能的数学模型、算法和硬件有多么先进，**没有场景丰富、精度高标注的数据，无人驾驶系统就永远只是一个新手司机**。


一般来说，数据分为真实场景数据和仿真模拟数据。前者顾名思义，就是在真实世界收集各种驾驶场景下的摄像头、激光雷达、雷达、GPS 定位等数据并进行人工标注，而后者则是利用各种游戏引擎模拟出现实世界的场景，进行预训练与测试。


用后者的数据来训练无人驾驶系统价格较为低廉，就像象棋学员和电脑对战，可以使之掌握象棋的基本规则并积累经验。然而要成为象棋大师，则必须去和人类棋手对战，比如用游戏引擎训练的无人驾驶系统，可以达到 90% 的准确率，然而最后 10% 的精确度，只能依靠真实的数据。


**但是，真实数据的成本非常高。**


我们来算一笔账：


一家德国无人驾驶公司，工程师开着测试车收集数据，企业支付工程师一小时工资至少 60 欧元（1 欧元约等于 8RMB）。


而「领头羊」Waymo 无人驾驶汽车已经行驶了 2000 万英里（2020.3,1 英里约 1.61 公里）。也就是说，单单收集数据本身 Waym**o 就要至少花掉将近** 2.4 亿 RMB！


而这只是开始，收集数据之后还需要进行各种人工标注，其中最昂贵之一就是**语义分割**（AI 术语）。


![img](https://pic2.zhimg.com/v2-38315ff22762c096dc797cc40177fe68.webp)

由上图可见，人类需要对每一个像素都进行分类，将它分为建筑、道路、行人等等，这样一张图大概会耗时一小时左右，而德国最低的时薪是 9.35 欧元。以次推算，像德国这样规模的国家，需要至少几十万张不同城市、不同天气、不同路况的图片数据，如果都交给德国人员标注，至少耗费数百万欧元。


除了语义分割，自动驾驶还需要很多其他的数据标注。由此可见，自动驾驶的开发是一件多么耗财耗时的事情，它需要大量资金持续输入，因此发展经常遇到瓶颈也是在意料之中。


最后，无人驾驶人工智能系统的训练流程大概是这样的：


* 先用几十万张标注好的图片与上百万张虚拟图片输入给系统训练
* 无人驾驶系统上路测试并收集反馈，重点记录效果较差的情况
* 收集至少上千张相似情况的图片并标注，用这几千张图片重返给 AI 系统训练，再上路测试，以此往复。

在这个循环中，**极端情况的场景是最「值钱」的**。因为系统只有吸取了错误的经验，才能避免再犯错误。


这也解释了一个很重要的问题：为何滴滴和 Uber 等打车平台都在研发无人驾驶?


**因为他们可以在自己平台的车辆上安装传感器，非常低成本地获取行驶数据，以及收集司机可能存在的极端情况数据。**


 到这里，我们便从底层业务逻辑重新认识了无人驾驶。


**四、小结：**回到最初的问题，无人驾驶离我们还有多远？
=============================


我认为，**L3 将会在 5 年内普及，**而 L4 和 L5，很遗憾，无法告诉大家答案。因为它还取决于一个非常关键的因素，那就是基础建设和政府的政策法规，包括 5G、物联网、智慧城市的建设进度等等。


在接下来的文章里，我会对上述提到的各种模块，包括仿真系统、感知算法、定位算法、行为决策、控制系统、车联网等等进行更详细的描述。读完这些章节后，你对无人驾驶不仅只有一个宏观的概念掌控，对最前沿、高精尖的技术细节也会有详细了解。


备案号:YX01APK9jDXMmP4pY


###### 2021-07-05 09:05
