## 7.思想实验六：纽康姆悖论｜我可以理性的选择吗？
理性在决策当中究竟扮演着一个什么样的作用；所有有理由的选择都是理性的吗？在同一个情境当中，理性所给出的选择答案一定会是同一个吗？当理性给出的选择答案之间出现差异，甚至有冲突的时候，那么究竟哪一个才能算得上是理性的呢？人又是怎么认识到哪一种选择是理性的？有没有可能对于某一个问题存在一个理性的解答方式，但是凭人的的思考能力，却永远没有办法把握到那种理性呢？


在理性选择理论当中，对于理性的理解十分形式化、简单、和明晰。大致地说，理性是一个选择主体根据自己的能力和资源，基于已有的信息，以最有效的方式，最大化地去实现自己的利益和偏好。


这种对于理性的理解，被哲学家们定义成「工具理性」。理性选择理论家们希望，根据这种定义，在某一个特定的环境中，信息充分的前提下，我们总是可以找出最理性的那个选择。如果不可以的话，一般要么是因为信息的不充分，要么是因为选择主体的理性能力不强。或者翻译成俗话，理性是那个总是能够帮助我们在不受骗、不犯蠢的情况下作出正确决定的能力和标准。


那么，是不是每一个信息充分，主体理性的情况下，人们都可以做出正确的决定呢？有没有可能虽然我们是在根据理性做出的选择，结果却永远选不到最好的那个结果呢？关于这个问题的回答，最著名的就是囚徒困境实验，它反应了在一个群体中，个人做出理性选择却往往导致集体的非理性。


这个实验在经济学、社会学、哲学、等等领域被一再提起，每一个学科从不同的角度都对这个悖论的产生和可能的解决有不同的答案。今天我们试着来讨论另外一个理性选择的悖论，看看有没有什么信息，是一个充分理性的主体没有办法用理性的方式处理的呢？或者说，理性选择是否存在着一种理解力上的界限，这种界限让选择主体永远无法有效地把某些最重要的信息转化成理性计算的一部分？


这个悖论的名字叫纽康姆悖论，提出者是一个理论物理学家，威廉 纽康姆。在上个世纪 70 年代，哈佛知名的哲学家罗伯特诺齐克在他的文章《纽康姆问题和两种选择原则》中提到了这个悖论对于理性选择理论的挑战，从此以后它在哲学界声名大噪。在今年年初，传说特斯拉公司的 CEO 伊隆马斯克用这个悖论与新任女友在社交媒体上欢乐互动，着实让纽康姆悖论又红火了一把。那么，这到底是一个什么悖论呢？


假设，有一个超级智能存在物，它可以是上帝，也可以是一个超级电脑，也可以是一个大怪物。有一天，这个存在物给你带来了两个箱子。其中一个敞开着，里面装了 1 万块钱，而另外一个箱子关闭着。里面可能是 10 万块钱，也可能一分钱没有。这个时候你必须做一个选择。你可以选择把两个箱子同时拿走，也可以选择去拿走那个紧闭着的盒子。


这个时候，吊诡的问题就出现了。这个超级智能存在物告诉你说，他是全知的，换句话说，他能够预测所有的人类将要做出的决定。如果他预测到你只会拿走那只关闭这个盒子，那么他就已经在里面放了 10 万块钱。但是如果他预测到你会把两个盒子都拿走，那么在那个关闭的盒子当中，他就一分钱也不放。同时在此之前，他已经和 99,990,000 个人进行过同样的游戏实验，他从来就没有弄错过。


现在的问题是，根据你手上已经掌握的所有信息，什么才是理性的、正确的决定呢？


有一种做决定的方式是只拿走关闭着的那个箱子。因为，如果在你面前的这个超级存在物，的确像他说的那样全知，那么他对于你的行为做出的判断应该是准确的，同时你也将用你自己现在的选择证明他做出的判断是准确的，那么你现在的行为也就会给你带来 10 万块钱的收入。


然而，与此同时，你也应该同样理性地想到，在你做决定的这个时刻，那个关闭的箱子当中要么是空的，要么其中装着 10 万块钱。无论箱子是空的还是装着 10 万块钱，你都应该把两个箱子一起拿走，因为你这个时候的决定已经不能再影响箱子当中已经存在的钱数了。


换句话说，最好的结果，你可能拿到 11 万块钱，最差的结果也能拿到 1 万块钱。而仅仅只拿走一只关闭着的盒子，恰恰是最不理性的做法。


然而，咱们再往深处设想一步。假设你真的把两个箱子一起抱走，这就恰恰验证了这个超级存在物所做的预言，而这个时候也就极有可能，那只关闭着的箱子，里面空空如也，一分钱都没有。可是如果选择只抱走一只关闭的盒子，从而验证了这个超级存在物的预言，你就有可能十分稳妥地拿到 10 万块钱。


现在为止，听故事的，你应该已经可以发现，在这个场景当中，究竟是该拿走一只箱子还是两只箱子，其背后的理性，推理已经形成了一个死循环。很多哲学家，甚至是宗教学家认为，这个悖论为我们揭示了人类理性的有限性。即便告诉我们，这个生物是全知的，这个信息却不能让我们的有限理性，有效地消化和处理，也不能纳入到理性思考当中。


在另外一些理性选择学家看来，这里的问题是我们并没有一个统一和谐的理性选择标准。因为在这个悖论当中两个以上的理性选择原则在起作用。第一个理性选择原则叫收益预期原则，这个原则告诉我们，我们应该根据利益获取的预期可能性来做出理性的选择。根据这个原则，我们应该选择只拿走那只关闭着的箱子，因为这个超级存在物做出正确判断的可能性非常非常大。


与此同时，还有另外一个理性选择原则，叫主导性原则。根据这个原则，如果不论情境如何，一个选择总是要比另外一个选择更好，那么你就应该选择它。根据这个原则，不管关闭着的盒子当中到底有多少钱，把两个盒子一起拿走，总是要比只哪一个更好，无论如何你总是会多拿 10,000 块钱。


纽康姆悖论引起了哲学家、数学家、和经济学家的热切讨论。同时，随着人工智能的长足发展，人们很好奇具有强大计算功能的人工智能究竟会如何处理这其中的理性选择悖论。更为有趣的问题是，如果在未来的某个时间，人工智能和大数据收集了有关于个人的所有数据，并成功地计算和预测出一个人的未来选择，我们究竟应该继续做理性判断呢？


在原有的这个例子当中，这个超级智能存在物还只是能够做出 99.99%的正确判断。如果有一天，我们面对的是一个能够做出 100%正确预测的对象，我们又该如何选择呢？仔细地思考一下，我们就会发现，这只会让两种原则之间的冲突变得更加尖锐和不可调节，究竟理性的选择是什么呢？英国《卫报》在 2016 年做了一个 3 万人的调查，结果发现只选一个箱子的人占到其中的 53%，二两个都拿的占 47%，算得上是两个旗鼓相当的答案，依然没有一个主流答案。


如果纽康姆悖论成功地向人们证明了个人的理性选择逻辑往往是有限的，存在缺陷。那么一个群体是不是可以避免这种理性的冲突，更好地解决选择问题呢？

