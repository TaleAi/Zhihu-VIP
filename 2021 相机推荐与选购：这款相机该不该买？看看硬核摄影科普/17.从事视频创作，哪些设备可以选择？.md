## 17.从事视频创作，哪些设备可以选择？
想做视频创作？请查收一份入门到进阶知识完整指南——万字长文解释视频制作中会用到的知识和术语，以及选择器材时应该注意的问题。


【有点长，可以先收藏下来，慢慢看】


不可置疑的是，这是一个视频的时代。


不论是相机还是手机厂商，每次发布会也会用很长的篇幅来解释他们产品的视频能力。


也很有多朋友为了更好的视频质量，不在满足于手机拍摄，开始选择单反或者微单开始自己视频的创作。


选购肯定也会遇到何种乱七八糟的参数，什么 10bit、422、super35 等等，这是都是什么，又有什么作用？


下面我们就来认真地讨论一下这些东西。


分辨率：4K 即正义？
-----------


当你在视频平台观看视频的时候，有时候可能会看到这个标志「4K 超清」。


![img](https://pic4.zhimg.com/v2-8769450aa59d0ca5ae5b10dfd9b6b79b.webp)

这就是分辨率——它也许是大家最熟悉的一个的参数，不论视频还是显示器，或者电视机都会用到这个参数，很简单也很容易理解，分辨率越高，视频画质越好。


通常还会用这样的一张图来解释不同视频分辨率的效果，这个分辨率被称为「输出分辨率」。


![img](https://pic2.zhimg.com/v2-63d19a938acf04054dbb8704a028f56e.webp)

有聪明的小伙伴就要问了，我的手机或者显示器也不过是 1080P 的，那还有必要搞 4K 么？


有必要。即使最终都是输出为 1080P 的，拍摄的 4K 素材包含更多的色彩信息，感官上会感觉更加的清晰，色彩更加丰富，这个过程就是超采，而且也方便你进行画面的裁剪或者稳定。


拍摄 8K 同理，即使最终输出的是 4K 的视频，也能获得更好的画面。但问题在于，能够拍摄 8K 的设备普遍不便宜，对于存储和处理的要求会更高。而且，除了相机之外，你还得更新电脑，买更贵的显卡和更大的硬盘才行。


所以目前来讲，4k 无疑更具有实用性，几乎每台手机，哪怕入门级别的相机也都开始普及 4K 视频了。


4K 分辨率其实是一个统称，画面横向像素在 4000 个左右，纵向在 2000 个像素左右的，都可以称之为 4k 分辨率，不同的设备和场景有不同的 4k 分辨率。


最为常见的是我们日常的网络视频以及很多显示器的比例——16：9，分辨率为 3840 × 2160，手机相机也通常也以这个分辨率捕获素材。


当然，还有其他规格的 4K 分辨率，可参考下表：


![img](https://pic3.zhimg.com/v2-af3f0ccd55f736c55a9aff497cb397fb.webp)

部分相机也能拍摄 DCI-4K 的视频，比如松下的 GH5s，以及 S1H 和 S5。 


**裁切与超采：为什么拍视频的时候画面会有变化？**
--------------------------


如果拿出你的手机，从拍照模式切换到录像模式，你会发现一个有趣的现象：画面的视角好像发生了变化。


![img](https://pic1.zhimg.com/v2-2159a426b2ac1893518510dcf706edcb.webp)

为什么呢？


其实也很好理解，拍摄 4K 视频，分辨率为 3840 × 2160，像素不过 800 万左右，但问题是现在的手机像素通常都在 1200 万像素之上，相机普遍的像素值则在 2000 万左右。


那多出来的这些像素怎么办？


第一种解法就是，多出来就多出来呗，不用就行了。于是就有了裁切这种方式，拍摄视频的时候，只使用中间那部分需要的像素就够了。


![img](https://pic2.zhimg.com/v2-d5714cc10f54d08c2c812f18e7ca355c.webp)

缺点显而易见，就是本来能够拍摄的到视角变小了。


比如，如果裁切系数为 1.7 倍，使用一只 24mm 的广角镜头，拍摄出来的画面相当于 40mm 镜头拍的，丧失了广角端。


顺便也提醒大家一点，厂家往往很鸡贼，会把这个裁切系数用很小很小的字体写在备注里。


![img](https://pic4.zhimg.com/v2-068dc03b9d905f8c22ba047c3e79ed67.webp)

既然集中使用中间的像素会丧失视角，那么我就尽量使用整个传感器呗。


于是「跳采」这种方式应运而生。简单来说，跳采就是每间隔几个像素记录一个像素点的信息，其它像素的信息就不要了，如图所示：


![img](https://pic1.zhimg.com/v2-be4ba61e95b05df9a86b795b5e3c7996.webp)

很棒，解决了视角裁切的问题，但是缺点也很明显，那就是舍弃了一部分像素的信息，不论是画质还是颜色上都会有所欠缺。


有没有更好的解法，有，那就是超采。


在理解超采之前，我们得先理解传感器是如何记录颜色的。


实际上，像素点是不会记录颜色信息的，只能记录光的强度，那如果想要还原真实世界的色彩怎么办？


这就不得不提「拜尔滤镜」了。在像素上放上滤色片，然后记录不同颜色的滤色片对光的过滤效果，可以得到颜色信息。但像素不是胶片的感光剂，摞三个滤色片在上边也不能记录色彩信息，于是拜尔想了一个办法，把 RGB 滤色器按照一定的方式排列在相邻像素上，这样就可以根据周边的颜色数值来算出一个「颜色」。


![img](https://pic1.zhimg.com/v2-100a5b349abf4ae8827f4466fa037d7d.webp)

既然是「算出来」的，那么也不是真实的。


但不可否认的是，只要我输入的条件越多，结果也应该更加准确、接近真实。


超采就是这么一个类似的过程——


采集传感器上所有像素的信息，然后根据周边像素的信息算出来一个数值，然后记录。


为了便于理解超采，我们举一个不太严谨的例子，假如现在有一个 3200 万像素的相机需要拍摄 4K 视频，也就是需要将四个像素变为一个像素。


假设四个像素的情况如图所示：


跳采，就是选择其中一个颜色直接记录，比如 1 中的红色；


超采，就是根据周边的的像素，来计算出一个颜色然后记录。无疑，这种方式可以获得更准确的颜色和更加锐利清晰的画面。


![img](https://pic1.zhimg.com/v2-c8a4b304c39057b7c2969636e8e13c3b.webp)

看起来很棒了，那超采就没有什么问题了嘛？


有。


由于超采需要计算，而计算是需要一定的时间的，就会导致「果冻效应」更加明显。


![img](https://pic4.zhimg.com/v2-3007463b2c61a81bf193d2a75ce8bb7e.webp)

你在车上拍的电线杆子，也就会更歪一点了。


![img](https://pic3.zhimg.com/v2-dd8628e731b1f5996284a27e88d24cd1.webp)

注意，即使具有超采功能的相机，也不是所有的视频规格都有超采，不同的分辨率和帧率下的设定会不同。比如索尼的大部分相机，4k 视频是从 6K 分辨率超采而来，但是 1080P 的规格就不是。


超采不一定会用到整个传感器，即使是超采，也会有画面裁切（但是这个比例通常很小），只要采集的像素比最终输出的像素多，就可以称之为超采。


**帧**率：**为什么是 23.98？**
----------------------


戈达尔说：电影是每秒 24 格的真理。


因为视觉暂留，一秒 24 帧的画面可以看起来流畅而且自然。


为了拍摄电影感的视频，你把相机的帧率调整为 24 帧，然后兴冲冲的拍了一段。但当你把视频导入到电脑上右键「属性」，或者把素材放到剪辑软件中的时候，你会发现视频的帧率是 23.98。


![img](https://pic3.zhimg.com/v2-b9d0c7005c57f8d03cc6f0257437dcc5.webp)

说好的 24p，怎么还差我 0.02，剪辑个视频都有中间商赚差价吗？


实际上，23.98 也是个近似值，准确的数值应该是 23.976。


为什么是这么一个奇葩的数字？


鲁（niu）迅（dun）曾经说过——一切看起来不合理的设定背后，都是历史遗留问题。


![img](https://pic2.zhimg.com/v2-25e99d5592096a57e04d4109972f2fcd.webp)

美国的电源频率是 60Hz，所以当年电视诞生后，电视的场频也是 60Hz。当时的电视采用的是隔行扫描，也就是一秒钟需要记录 30 张画面，也就是 30fps。


但是后来彩色电视诞生了，需要传输和记录色度信息、彩色副载波与亮度信号和音频载波之间的相互干扰。


![img](https://pic1.zhimg.com/v2-ba5b52d04e561442ef26508eac70cbc6.webp)

工程师为了解决这个问题，就把频率下降千分之一，场频变为 59.94，同理，帧率就是 59.94×1/2=29.97，电影的帧率也下降千分之一——24/1.001=23.976，看，这个神奇的数字出现了。


但当人们想用电视看电影的时候，问题就出现了，电视是 29.97，电影是 23.976，帧率不一样怎么看？


![img](https://pic2.zhimg.com/v2-94cbf9eb5952cab1ef713e54f80200a2.webp)

也就是说，电影画面每四帧要塞到电视的五帧里，这就有了 3：2 Pull down 的技术。


![img](https://pic4.zhimg.com/v2-30f7132f59b7b48a7f08c5259b1baf7d.webp)

还记得之前说的隔行扫描吗？


每个画面经过隔行之后会产生两个画面，然后按照「2323」的方式排列，最后就可以把四帧的画面塞到五帧中。


虽然说已经是数字时代了，但是还有一些地区和在使用模拟信号的电视或者广播，所以 23.976 这样的帧率的兼容性会更好的一点。


其实还有一个最为主要的原因，目前的消费领域的拍摄设备，基本上都是 23.98（23.976），真 24p 的相机或者录像机往往比较贵。不过就相差这么一点，看不出来什么的。


视频的制式根据各国使用的电源频率不同，分为 PAL 制和 NTSC 制。前者有中国和德国为代表，电源频率为 50Hz，视频的帧率有 25P、50P 或者 100P；后者以美国和日本为代表，电源频率为 60Hz，视频的帧率有 30P，60P 或者 120P。


![img](https://pic4.zhimg.com/v2-5192d1a857baa5112c14189722369f74.webp)

这就是有的小伙伴经常会问到的一个问题，为什么我的相机宣传可以拍摄 120 帧的视频，为什么菜单设置里只有 100P——切换一下制式就好了。


这里必须得吐槽一下，索尼的相机，切换个制式还得格式化，搞不懂为什么会有这么奇葩的设定。


有人又要问了，那要使用 N 制还是 P 制？其实现在的视频大多是网络使用，是 N 制还是 P 制关系不大，选哪个都行，开心就好。但如果你有电视或者广播播放的需求，那还是得选择对应的国家制式，以免后期麻烦。


如果有多个设备，建议拍摄制式统一。


另外，还有一点需要注意，如果你发现拍摄的场景有照明灯光，画面中出现闪烁的情况，建议还是调节成当地的制式，帧率和电源频率匹配就可以解决这个问题。


我们经常说的慢动作拍摄，其实就是一秒钟拍摄更多的画面，比如 120 帧，然后播放的时候按照正常的帧率播放（24 帧），这样本来 1s 的画面需要 5 秒的时间播放，自然就慢了。


这个过程也就是我们所说的升格。


**有升格就有降格**，相反的，一秒钟记录更少的画面，然后以正常的速度播放，就会有视频加快的感觉，最常见的降格是延时摄影。


但是，更高的帧率和分辨率会导致更大的数据量，在很多基础的相机上，高帧率和高分辨是不可兼得的，需要作出取舍。这也是为什么目前大家对 4k/60 这个参数情有独钟的原因，因为它在画质和帧率上达到了一个不错的平衡。


码率：**为什么我的 4K 这么差？**
--------------------


我们可能有时会发现，手机拍摄的 4k 画面，有时候还不如相机拍摄的 1080P，但按理说，4k 的画面要比 1080P 好很多，这是什么原因呢？


决定画质的，除了分辨率，还有码率。


这也就是一些国内的视频网站，所谓的超高清的视频的画面看起来并不那么高清的原因，除了分辨率虚标之外（720P 就是超清，1080P 就是蓝光，那 4K 不得起飞了？），视频的码率也惨不忍睹。


![img](https://pic2.zhimg.com/v2-0e82892820238f2a1098299ceafdbccb.webp)

大多数的视频码率在 2M-4M 之间。


![img](https://pic1.zhimg.com/v2-e7998ece216582857594143f4ac5a7e5.webp)

B 站的码率算是良心的了。


码率，就是一秒钟记录的数据量，数据量越多，画质越好，它决定了你视频文件的大小。通常来说，手机这种设备的码率厂家已经给你写死了，没有办法调节。


那么，问题来了，对于相机这类设备来说，是否需要将码率设为最高呢？


答案也不一定，一切都要按需出发。


在一定的分辨率下，不断提高码率所带来的画面提升已经肉眼不可见了，文件体积却在不断地增大。因此，一个比较实用的做法是使用你手头的机器，用不同的码率拍摄一段看起来复杂的画面，然后正常进行后期调色，找到一个你分辨不出来画面差异的码率，用它就行了。


**封装格式：找一个盒子装起来**
-----------------


先来说格式封装，这个是大家最常见到的东西，也就是文件的后缀名。常见的格式有 MP4、MOV 和 FLV 等。


本质上，你可以把格式理解为一个容器，可以装进去所有关于视频内容，除了帧画面，还有音频甚至字幕。


比如从网上下载电影来看，很多都是 MKV 这种格式，可以塞进去多轨音频甚至多轨字幕，这也就是为什么有的电影能够切换声道的原因。


**编码：存储的方式**
------------


下来说说编码，也就是记录画面的方式。


视频有两种记录的方式。一种是帧内编码，比如苹果的 PRORES，这种方式很好理解，就是直接记录每一帧画面，后期电脑直接按顺序播放这些画面就可以了。优点就是几乎不需要什么算力，播放起来很流畅，缺点就是会占用更大的空间。


![img](https://pic2.zhimg.com/v2-107e1167d59fe37db487bf6bd3e1647b.webp)

这也就是为什么同样的配置的电脑，往往使用 Final cut Pro 剪辑要比 Adobe Primier 流畅很多的原因，正是因为 Final Cut Pro 使用了 PRORES 的编码方式，但本质上，这是一种「以空间换速度」的做法。


很多小伙伴们用 Final Cut 剪视频时，剪到一半突然发现硬盘空间没了，就是这个原因。此时可以在剪辑完成后删除这类优化代理渲染文件来节省空间，不过，如果你有大量的素材，那建议还是搞个外置的大容量 SSD 或者直接连接 Nas 剪辑，体验会更好。


PRORES 是一种中间编码，仅用于中间的视频编辑过程，也就是说，最后视频输出还得靠 H.264。


H.264 是一种帧间编码。简单来说，它只记录每帧之间的变化值，然后解码器根据变化来「算出」中间的画面。


![img](https://pic2.zhimg.com/v2-4b88165158d23e9ec29873dfc8649882.webp)

比如，我拍摄一个采访视频，嘉宾基本上坐着不动，背景啥的都没有变化，只记录变化部分的最大好处是文件体积就会小很多，但是解码播放时，却增加了算力的要求。


H.264 应用十分广泛，几乎在所有的设备和产品上都有应用。


![img](https://pic3.zhimg.com/v2-e81d132f9c1ee88fd1547edfd22aec91.webp)

下一代是 H.265，可以做到更好的体积压缩和更好的画质。但目前的播放和处理设备对于 H.265 的支持都不太好，也就是说，你直接用当前的电脑剪辑 H265 编码的视频，会卡的惨不忍睹。


卡了怎么办？除了换电脑之外，买显卡之外，还可以通过剪辑软件生成代理素材来剪辑，这是一种「以时间换性能的做法」。


 


![img](https://pic4.zhimg.com/v2-7ce404fd20e00b703b55d6eee676ea02.webp)

**色深与色度采样：10bit 422**
---------------------


10bit 422，8Bit 420 这是我们在看相机参数时，经常会看到的一串数值。


这到底说的是啥？


——色深，越深越好。


先说这个 10bit 的色深。如果你经常使用 Photoshop 或者一些设计软件，一定会经常看到#FFB6C1 这样的数值，它们称之为色值，通常由 6 位十六进制字符代表，红绿蓝每种颜色占用两位。


![img](https://pic1.zhimg.com/v2-8ccb926b8ae9ec8fc94300940a8cda4d.webp)

也就是说，每一种颜色有 16×16 种变化，这个数值正好是 2 的 8 次方，所以这种颜色被称为 8 位色深，也就是 8bit，8bit 色深的颜色一共有 256×256×256=16,777,216 种颜色，也就是我们经常说的 1600 万色。


虽然看起来也不少了，但是在实际的拍摄体验中，尤其是渐变的场景，后期稍微拉一下，就会遇到色彩断层的问题。


![img](https://pic2.zhimg.com/v2-29218f219d443206dfba8e207500167e.webp)

而 10bit 最终的色彩总量可以达到 10 亿色，由于颜色增多，色彩的过渡会更加的自然，哪怕最终输出的还是 8bit 的画面，依旧可以获得很不错的画面。


**色度采样：谁还不是为了省钱啊！**
-------------------


为了数字化的记录颜色，人们搞出了「色彩空间」这样一个模型。


![img](https://pic2.zhimg.com/v2-00191b5964057d7a565faf91f2ac4e56.webp)

不同的色彩空间有着不同的特点，应用于不同的领域：


我们最为熟悉的 RGB 是一种加法色，应用最为广泛，设备显示、图像处理都有它；


CMYK 是一种减法色，通常用印刷行业；


RGB 发光屏幕的加色模式，依赖于光线；CMYK 是一种颜色反光的印刷减色模式，依赖于颜料。有所依赖就会有所不足，所以就诞生了 Lab 模式，理论上 Lab 可以包含所有色彩。


但是，在电视或者数码摄影系统中，我们通常上使用 Y'CBCR 这种色彩模式。


实际上，Y'CBCR 不是一种绝对色彩空间，而是 YUV 压缩和偏移的版本，但由于 Y'CBCR 的应用实在是太广泛了，所有大多时候，我们口中所说 YUV 指的就是 Y'CBCR。


![img](https://pic3.zhimg.com/v2-cf13b36a7cb58d2d485268ced2e17121.webp)

其中：


Y'代表光的浓度，也就是亮度，这个值是非线性的；


Cb 和 Cr 代表蓝色和红色浓度的偏移量，包含色度和色差信息。


常见的格式有以下几种，用一个三分比值表示，比如 4:4:4，4:2:2，4:2:0 等。


第一个值为区域的宽度，也就是区域的像素数量，通常上为 4；第二个值是第一行像素的色度抽样数目；第三个值是第二行的色度采样值。


![img](https://pic2.zhimg.com/v2-51bc1cee29e471f6290482d466644d2f.webp)

我们来看 4:4:4 这种格式，区域的宽度为 4 个像素，第一行抽样的数值为 4，第二行也是 4，也就是所有的信息都被采集到了，这是一种对于色彩细节保留最好的格式。


同理，4:2:2 和 4:2:0 的取样情况如下：


![img](https://pic3.zhimg.com/v2-5aa705956b991fb5745d6da454d49234.webp)

可以明显看到，4:2:2 损失了 50% 的信息，而 4:2:0 几乎损失了 75% 的信息。但即使如此，损失了 50% 的 4:2:2 也被视为高品质的专业视频格式，比如索尼家的微单相机，目前应该只有 A7S3 和 A1 支持 4:2:2 的视频格式，其他的主流机型，目前还停留在 4:2:0 上。


在比较图像质量时，比值才是重点，你可以把 4:4:4 称为 1:1:1，但是习惯和约定俗成的情况下，取样的总样本范围还是为 4，这也就是为什么没人 16:10 称为 8:5 的原因，无他，习惯耳。


那为什么要采样，搞得这么复杂？


鲁（niu）迅（dun）又曾经说过——人们的很多选择，多半是为了效率（省钱）。


![img](https://pic3.zhimg.com/v2-8cf9def061c13b030c760709d219fcbe.webp)

使用 4:4:4 不仅对拍摄器材的性能要求极高，存储上也吃不消。


还有一个最主要的原因是：眼镜对于微调的色度不太敏感。也就是说，Cr 和 Cb 可以用一点点的样本就能进行编码，而且可见的质量损失微乎其微，却节省了大量的数据量。


这也就是你即使用保留了 25% 的色彩信息的 4:2:0 去拍，实际的观感也没有那么差的原因。


但是你如果要进行复杂的后期，甚至抠像特效的时候，你就会发现，4:2:0 的画面用起来就有点捉襟见肘了，还是得上 4:2:2。


**RAW，Log，Rec709，HLG 又是什**么
---------------------------


**RAW：（生）肉**


玩摄影的朋友，想必对于 RAW 很熟悉了，它记录了传感器采集到的所有的光线的信息。


严格来说，RAW 并不是一种图片格式，而是一个数据包。


拍的 RAW 格式的视频与图片类似——本质上视频就是一张张图片拼接起来的嘛。


 RAW 视频拥有的最大的后期空间，但是能够支持拍摄 RAW 视频的器材不多，都是比较专业的摄影机，比如 RED,、ARRI 之流，十分昂贵。


有一个例外就是适马 fp，机身小巧也不算贵，能够拍摄 cinemaDNG 序列（也算是一种 RAW 视频了）。


其实所有的拍摄设备，都有 RAW 的这个过程，那为什么不把 RAW 数据直接给你呢？


因为 RAW 是个数据量杀手，你刚塞进去一张 128G 的 SD 卡，还没有一分钟，嚯，卡满了，后期处理也是一个大难题，流程繁琐，并不适合大多数据消费者使用。


**Log：指数观察世界**


人眼能看清楚明亮的天空，也能辨别阴影的细节。这就说明人眼对于光线的感知并不是线性的，这也就是中性灰是 18%，而不是 50% 的原因。


为了尽量的拟合人眼识光线明暗的特点，人们找到了 log 这个函数来模拟，为的就是记录更多的明暗数据，换句话说，就是把暗部拉上去，把亮度压下来（是不是像极了后期照片时减高光，加阴影的操作？），来让画面有用更高的动态范围。


![img](https://pic1.zhimg.com/v2-c2673d86ba50cff9df254f9d98f001ec.webp)

不同的厂家有着不同的 Log 曲线，比如佳能的是 C-log，索尼家的是 S-log，富士家是 F-log，松下的是 V-log（注意不是拍吃饭旅游的那个玩意）。


即使是同一家厂商，Log 曲线也有不同的版本，比如 C-log 就有 1，2，3 的区别，在暗部、亮部的捕获表现上都会有细微的差异。


但是直接观看 Log 画面，会显得十分的「灰」。


如何观看正确的色彩呢？这时候 LUT 就登场了。基本上所有的厂家都会提供自己 log 模式的还原 Lut，可以很轻易在官网找到。


![img](https://pic4.zhimg.com/v2-b17e849c2c54abb8ff752438b7ca82e2.webp)

日常使用 Log 拍摄时，需要注意以下两个问题：


起跳 ISO，比如索尼的 Slog3 的起跳 ISO 是 800，如果在大白天也想使用大光圈拍摄，那么减光镜就是不可或缺的配件；


对于精准曝光要求极高，所以你得上监视器或者使用直方图，斑马纹来确认你的曝光是否准确。


相信我，大多数新手拍 Log 都会在精准曝光上载无数个跟头，一个比较实用的曝光的经验是：在保留画面信息的基础上，尽量向右曝光。


有些相机厂商虽然也支持 RAW 外录和 N-log，但需要你「花钱」升级固件，比如尼康 Z6/7。


**Lut：是滤镜吗**


Lut 即 look up table，直译为颜色查找表：输入一个值，然后换成另外一个值，从而达到调色的目的。


是不是看起来跟滤镜的作用一样？但实际上原理是相当不同的。


你可以简单理解为，LUT 是颜色替换，而滤镜是计算。


当然，你也可以在网上找到无数的 Lut，有兴趣的话，也可以自己做一个。


**HLG**


随着技术的进步，HDR 设备开始普及，包括你手头的旗舰手机几乎都开始支持 HDR 了，相机们也加入了 HDR 视频的拍摄能力。


这里就不得不提 HLG 标准了，HLG 是 BBC 和 NHK 联合开发 HDR 标准，提供了编码宽动态范围（HDR）的能力，也保留了标准动态范围（SDR）的支持，使得他的兼容性很好。


而且，HLG 标准并不需要你掏专利费，所以很多厂商也纷纷投入了 HLG 怀抱，比如索尼，松下，甚至大疆的大多数设备，都可以拍摄 HLG 视频。由于采用的是相同的标准，即使是不同厂家的设备拍摄的 HLG 视频，后期在颜色匹配上也比较完美。


p.s： 


iPhone12 拍摄的 HDR 视频，标准为杜比视界。实际上，iPhone12 拍摄的也是 HLG 视频，只不过加了一层杜比视界的元数据层。


相对 Log，HLG 还有以下两个特点：


* 画面没有那么灰，颜色显示较为正常，甚至不用处理也可以直出使用；
* 没有起跳 ISO 的限制，使用起来比较方便。

HLG 同 log 一样，也有 HLG1，HLG2，HLG3 的区别，在暗部和亮部的保留和取舍上各有倾向，要依据你实际拍摄的画面而定。


对于日常使用或者新手来讲，HLG 明显更加友好。


**色彩标准：Rec.709**
----------------


这是一个 1990 年发布的统一色彩标准，色域和 sRGB 相同，并不大，多数设备拍摄的素材都可以轻松超过，但是一些显示设备或者产品服务，就只支持这个标准，大于这个标准拍摄的画面，实际播放是没有任何意义的。


也就是说，为了能在电视和普通显示器上正确的显示色彩，就得按照 Rec.709 的规定来。


但是随着 HDR 设备的普及，就连 B 站也开始支持 HDR 了，Rec.709 这个标准貌似不太够用了，于是新的标准也诞生了，BT2020，支持 4k，8K，最高 120 帧的速率，以及 12 位的深度。


![img](https://pic1.zhimg.com/v2-b6eb1655847794c5493a970ee01b09b5.webp)

所以你在拍摄 Log 或者 HLG 视频时，可以将色域选择为 bt2020，这样可以在 HDR 显示上获得更好的观影体验。


**快门角度还是速度**
------------


照相机除了拍照也可以拍视频，而电影机也可以拍照，那他们的区别到底是什么？


其实，最明显的一个操作逻辑上的区别，就是快门。


如果你用过 BMPCC 之类的摄影机，在快门参数的调节上，使用的是快门角度。


这个概念其实来自于电影拍摄，电影为 24 帧每秒，那每一帧的快门速度就为 1/24s。但是人们发现这个速度的动态模糊太大了，导致视频看起来一点都不清晰。


那么如何调节胶片拍摄的时候的快门速度呢？加上一个旋转快门就好了。比如这个 180°的快门装置就能遮挡一半的光线，让快门速度来到 1/48s。


![img](https://pic2.zhimg.com/v2-a146a77e88442e02f140a78b37b6bfba.webp)

当然也有 45°的快门和 270°的快门，调节快门板的角度就好了。


人们发现，180°的时候，在画面锐度和动态模糊间达到了一个完美的平衡，所以，以前的电影机和摄影机基本上都是以 180°的快门角度来拍摄视频。


使用摄影机拍摄时，设置为 180 度的快门角度就好。但是对于普通相机来说，快门速度要按照二倍帧率的倒数来设定来达到类似的效果：


* 24 帧，快门速度为 1/50s
* 60 帧，快门速度为 1/120s
* 120 帧，快门速度为 1/250s

不过，当前的相机基本上都提供能自定义拍摄参数的保存，方便你快速切换。


**不可忽视的限制**
-----------


使用相机或者单反拍视频时，总是存在各种各样的限制。


这个限制主要是来自于数据量，拍摄高分辨率高帧率的视频，会产生很大热量，散热如果不给力的话，相机就会做录制时长的限制，比如很多相机只能连续录制 30 分钟的视频，要么就直接给你来一个过热警告。


另一个是高分辨率高帧率的视频对存储卡的写入速度也提出了要求，而高速卡的价格往往也不便宜。而且数据量的增大会增加相机的运算负担，一些功能在高分辨或者高帧率下就被禁用，比如：


* 大部分相机在 1080P/120 帧的模式下，无法启用人脸/人眼对焦，只能使用最为传统的反差对焦；
* 代理视频的录制功能，只能后期通过电脑生成代理视频。

**是时候按下录制键了**
-------------


无论你使用怎样的设备，无论这个设备的性能如何，最重要的是出去拍。


以上讲的所有知识，都只是为了让你获得一个更加好看的画面，让你的画面更加锐利，减少噪点，但是画面永远不是全部，只是锦上添花的部分。


更加重要的是内容和故事。


如何讲好一个故事，才是你应该不断思考的问题。


**视频相机的选择**
===========


**1. 富士 XS-1**0
---------------


APS-C 画幅最火的机型之一。以至于在上市初期（2020 年 10 月中旬），还有缺货的情况存在，受欢迎程度可见一斑。


2600 万像素 X-Trans CMOS 传感器，采用 X-Processor 4 影像处理器，视频方面，支持 4k 30p， 1080P 的慢动作拍摄支持到 240 帧，侧翻屏幕，5 轴防抖，最高能够提供 6 挡的防抖。


而且作为富士的机型，还内置了 18 种胶片模拟，即使是小白新手或者不怎么熟悉后期的同学，富士的直出色彩可以很大程度上提升拍摄的体验和乐趣。


![img](https://pic3.zhimg.com/v2-2601997266884ce9d25183d60686d008.webp)

缺点：与 XT 系列的转盘式操控方式不同，有可能是最不像富士的富士相机。


售价：单机身 6999 元，套机（15-45 镜头）7699，年货节应该有 200 元的优惠。


**2. 索尼 A7**C
-------------


全画幅的心脏，APS-C 的体型，是目前机身最小的全画幅相机之一。C 代表 Compact，紧凑之意。


性能上几乎与索尼热门机型 A7III 没有什么差异，属于那种看起来很一般，但是用起来真香的机型。


![img](https://pic4.zhimg.com/v2-fc02a335d11fc5b107cb8218382ff725.webp)

采用 2420w 像素的全画幅传感器，机身重量 424g（索尼 A7III 为 565g），A7C 搭配了多角度的侧翻屏幕，可以翻折的角度比 A7III 大很多。视频方面，支持 4K/30P，1080P/120p Log 视频的拍摄。


相比 A7III，A7C 的主要优点是：


* 更小更轻的机身，便于自拍的翻转式屏幕；
* 支持视频拍摄的眼部追踪，以及没有限制的视频拍摄时间，同时支持竖排视频；
* 支持记录陀螺仪数据，可以在后期中进行更好的防抖。

相比 A7III，A7C 的缺失了以下特性：


* 最高 1/8000s 的机械快门速度；
* 双卡存储；
* 更大尺寸的 EVF；
* 更多的自定义按键。

总的来说，相比于 A7III 来说，A7C 在性能上没有阉割多少，而且部分升级能够更加提升拍摄的体验。索尼 A7III 上市很久，价格依旧坚挺，A7C 从售价上也比 A7III 更优惠一些。


售价：单机身 11988 元，套机（28-60）售价 13599 元。


**3. 佳能 EOS R**6
----------------


全画幅的微单相机，索尼 A7M3 很长的一段时间里都是霸主的存在，直到 EOS R6 的到来，虽然晚到了很久，但是出色的性能却让人久久不能忘怀。


可以说，目前全画幅入门基准相机，R6 是最值得购买的一款。


EOS R6 于 2020 年 7 月份发布，作为 R5 姊妹机型，除了像素上的差异，不能拍摄高像素和 8K raw 视频之外，其它参数几乎与 R5 没差多少。


![img](https://pic1.zhimg.com/v2-2b65703d52768b01d3afeef0241b999a.webp)

采用 2010 万像素全画幅传感器，这颗传感器是基于佳能顶级旗舰单反 1DX Mark III 定制而来，可以理解为具有相同的画质和速度，使用机械快门支持 12 张每秒的拍摄，使用电子快门支持 20 张每秒的拍摄，连拍过程中支持连续对焦。


电子取景器采用 392 万的 OLED，最高可达到 120 帧每秒的刷新率。对焦方面，搭载了全新一代的全像素双核对焦，可以识别人脸，面部，甚至支持猫，狗，鸟的识别。自动对焦系统可在-6EV 的暗光环境下使用。


支持机身防抖，搭配对应的 Rf 卡口的防抖镜头，最高可达到 8 级防抖，视频方面，支持 4K/60P，1080P/120 帧视频拍摄，支持 HDR PQ 10bit 4:2:2 视频的录制。机身采用防滴溅设计，也带来了之前 EOS R 缺失的双卡槽。


缺点：


* 不支持 RAW 视频的记录；
* 机身材质非金属；
* 拍摄 4K/60 帧视频时，依旧有过热的问题，大概能拍摄 25 分钟左右会出现过热警告。

售价：单机身 15999 元，单机身+转接环，17000 元左右，套机（24-105 STM) 18000 元左右。


**4. 佳能 EOS R**5
----------------


佳能的 5 系，一直是消费旗舰的代表，微单也不例外，佳能最新推出的 EOS R5，可以称之为「微单机皇」。


采用有约 4500 万有效像素新型 CMOS 图像感应器及高性能 DIGIC X 数字影像处理器，最抢眼的参数莫过于支持 8K raw（无裁切）的内录，意味着你视频后期会有极大的空间，无论是自由裁切，还是模拟变焦，还是模拟运镜（推拉摇移），都会得到不错的效果。


4K 视频也是由全画幅的 8K 分辨率超采而来，可以获得更加锐利清晰的画面。支持 4K/120P，10bit 422 视频的录制。可以在 4K 的分辨率下，获得 5 倍的慢动作升格视频，支持 C-LOG 和 HDR 视频的拍摄。


视频的参数很炸裂，但是实际上作为一款相机来说，R5 更像一台水桶机 ，拍照方面也很强，支持新一代的全像素双核对焦，支持人眼和动物眼镜的识别，连拍速度方面，在连续对焦的情况下，可达到 20 张每秒的拍摄。


搭配支持防抖的 RF 镜头，最高可以达到 8 级防抖，无论是在照片和视频上，都可以起到很好的稳定作用。


优点：


* 支持 8K raw，4K/120 帧视频拍摄；
* 全新的全像素双核对焦系统；
* 最高支持 8 级防抖。

缺点:


* 过热问题。根据佳能官方的数据：8K Raw 拍摄 20 分钟后过热，8K30p 20 分钟过热，4K60p 35 分钟过热 4K30p 30 分钟过热，而且过热后会自动关机，需要很长的冷却时间才能再次启动。所以这样的参数更适合拍摄短镜头。
* 如果需要录制高规格视频（ 8K Raw 和 8K30p，或者 4K120p），需要 CF Express 存储卡，而这个存储卡是比较贵的，一张 512G 的存储卡售价大约为 5000 元。
* 编辑 8K raw 和 4K/120p 视频，需要性能较强的电脑，也许还得来一次电脑的升级。

![img](https://pic1.zhimg.com/v2-3d5a7de9347bc5b58ffd1c973cc6f4b8.webp)

售价：单机身售价 25999 元，套机（RF24-105mm）售价 28599 元。


市场现状：


由于疫情的影响，R6 和 R5 的及相关镜头的售价，目前来看还是比较「硬」的，尤其是 RF 镜头，加价购买更是常态，有需求的同学可以不妨先等等。


**5. A7SIII**
-------------


作为 A7S 系列的第三代机型，可谓是千呼万唤始出来，距离上一代机型发布之后五年才推出，可以说吊足了大家的胃口。


首先总结一下，这个机型只适合视频用户，如果你想兼顾拍照，建议还是选择其他机型，因为像素只有 1200 万。


支持 4K/120P，1080P/240P 的升格拍摄，而且支持自动对焦，采用新的散热方案，理论上可以拍到电池没电，存储卡满，所以这台机器更适合拿来干活。同时提供了侧翻屏幕，方便各种角度的构图取景，重新设计的三段式菜单，而且屏幕终于支持触控了。被吐槽了多年的菜单终于有了优化改进。


另外，电子取景器的像素达到了 944 万点，可以说是目前最优秀的电子取景器。


优点：


* 优秀的视频性能及散热能力。

缺点：


* 1200 万像素；
* CF express type A 存储卡较贵，160GB,4199 元，读卡器：1399 元。

![img](https://pic1.zhimg.com/v2-6e7c15c2d7fd5f249f9e968f6321d35e.webp)

售价：单机身 23999 元。


**6. 松下 S**5
------------


作为松下全画幅微单的最新机型，兼顾了视频和照片的能力，而且甚至比 M43 的 GH5 有着更小的体积和更轻的重量。


采用的传感器是索尼 A7M3 同款的 IMX410，静态照片画质上完全没有任何可以担忧的。视频方面很给力，双原生 ISO（ISO640 和 4000），可以拍摄无限制时间无裁切 4:2:2 10bit 4K30P V-Log 视频；也可以拍摄 4:2:0 10bit 4K60P V-log 视频，但是有着 1.5 倍的裁切，有着 6.5 级防抖、180FPS（7.5X 升格）的全高清视频。


一万块钱的给到这样的视频参数，完全可以说是丧心病狂。得益于松下一直以来在视频上的投入，各种视频的辅助功能也是一应俱全。


缺点依旧是对焦，完全比不过索尼和佳能。


![img](https://pic2.zhimg.com/v2-6dc4e6399bc41c0683ee5d09020b5e6e.webp)

总之，虽然不完美，但依旧是一台好相机。但是目前 L 口的镜头较少，目前来看最好的方案，就是新款的 20-60mm 和适马的 45mm F/2。如果这两个标准变焦和定焦能够覆盖你的需求，那么 S5 是一个不错的选择。


**7. 适马 FP**
------------


其实称适马 FP 为电影机更加适合，因为整个相机的设计思路更像是用电影机的方式来设计。


采用与 A7M3 同款的传感器，2400 万像素全画幅，最大的特点就是机身极小，整机重量 730g，而且方方正正，没有多突出部位，在这种设计之下，没有模式拨盘，没有取景器，也没有肩屏，和手柄。


但是他的扩展能力极强，可以扩展各类的设备。但是由于取消的机械快门结构，最高的闪光快门速度不过 1/30s，这对于有闪光灯拍摄的需求来说可以无法接受。


虽然机身小巧，但是散热十分给力。


视频方面，可以支持 4k 30P 和 1080P/120p 的视频录制，同时可以外接键盘直接录制 Cinema DNG（但是不支持 log），这就决定了视频素材有极大的后期空间，但是也会带来硬盘容量上的压力。


目前单机售价为 9999 元。


优点：


* 支持录制 Cinema DN；
* 机身小巧，扩展性强。

缺点：


* 视频连续对焦几乎不可用。
* 视频没有更多的压缩选项，需要搭配更多的附件才能发挥出实力。

备案号:YX015j5PRrYxP977O


###### 2021-07-13 08:46
